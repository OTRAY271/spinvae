{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Reconstruction - auto encoders\n",
    "\n",
    "## Architecture générale : CNN ?\n",
    "\n",
    "Avant de passer à la régression de paramètres de synthé, on va d'abord entraîner un AE à reconstruire les (mel-spectrogrammes) des sons des presets du DX7.\n",
    "\n",
    "Choix du AE :\n",
    "* Encodeur/décodeur à CNN sur spectrogramme (FlowSynth, IRCAM 2019)\n",
    "    * Encodeur (décodeur idem) : 5 couches de 64 canaux, kernel 7, stride 2, dilation 2\n",
    "    * WAE, qui d'après (Esling et al. 2020) donne au final les meilleures régressions de paramètres de synthé ?\n",
    "    * Divers VAE avec flow, qui d'après (Esling et al. 2020) donnent la meilleure reconstruction audio ? (avec metadata....)\n",
    "        * (https://acids-ircam.github.io/flow_synthesizer/#models-details)\n",
    "* WaveNet\n",
    "    * 10 couches de kernel 4, stride 2, dilation 1. Nombre de canaux va de 128-512 à 1024 pour mix final\n",
    "    * Temporal encoder à convolution sur raw audio\n",
    "        * Comparer le *baseline CNN encoder* avec le *temporal encoder* sur spectrogrammes ? Même si Google Brain/DeepMind restent sur du CNN classique \n",
    "    * Décodeur WaveNet : beaucoup trop lourd\n",
    "* WaveNet baseline (and temporal) :\n",
    "![](https://pbs.twimg.com/media/C8spAMCXYAAX6ml.jpg)\n",
    "\n",
    "\n",
    "## Architecture : fonctions d'activation, BN\n",
    "* Dans les CNN : tester ReLU vs. LeakyReLU vs. ELU (similaires, mais coût de calcul croissant)\n",
    "* Dernière couche d'encodeur : aucune activation ni BN. On veut effet récupérer mu et logvar sans distorstion et sans BN\n",
    "* Dernière couche de décodeur\n",
    "    * Soit E/S avec zero-mean et unit-variance, et alors il ne faut aucune activation\n",
    "    * Soit E/S entre -1 et +1, sans activation\n",
    "    * Soit E/S entre -1 et +1, avec tanh en sortie. Tanh semble rendre l'entraînement instable, avec perf. idem\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions en suspens :\n",
    "* Est-ce c'est intéressant d'avoir un décodeur qui génère une image légèrement trop large ? (Pour limiter les effets de bords sur les dernières couches)\n",
    "* Intégrer le pitch qqpart va sans doute beaucoup aider\n",
    "    * Pour comprendre tous les params, plusieurs notes//plusieurs pitch sont probablement nécessaires\n",
    "* Problème général des synthés qui peuvent générer le même son de plusieurs manières différentes\n",
    "\n",
    "## Dimension de l'espace latent z :\n",
    "* FlowSynth (Esling et al. 2020) prend $d_z = d_v$ avec $v$ le vecteur des paramètres. En effet, ils ont voulu un flow inversible entre z et v\n",
    "    * $+$ : traduction facile d'un preset en vecteur latent z\n",
    "    * $+$ : de chaque côté de l'interpolation, on a *exactement* le preset d'origine...\n",
    "    * $+$ : chaque réel $z_i$ peut se rapprocher d'une dimension perceptuelle de haut-niveau\n",
    "    * $-$ : limite de taille de l'espace latent\n",
    "    * $-$ : autant de \"macro-contrôles\" que de params de synthé (solution possible : interp miem...)\n",
    "    * $-$ : MSE assez forte sur valeurs de paramètres (flow inversible pas si puissant qu'un NN)\n",
    "* WaveNet AE (Engel et al. 2017) encode un z à 2 dimensions : 16 dimensions par timestep, 125 timesteps de 512 samples (32 ms à 16kHz)\n",
    "    * Un latent z comme ça permet sans doute de bien représenter attaque/sustain/decay, LFO, etc ? Et donc d'obtenir une bonne reconstruction\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss\n",
    "\n",
    "### Coût de reconstruction\n",
    "* MSE Loss\n",
    "* Spectral convergence ?\n",
    "\n",
    "### Régularisation\n",
    "* D_KL\n",
    "    * VAE avec normalizing flow : est-ce qu'on fait la régularisation au début ou à la fin du flow ?\n",
    "        * Pour WAE : même problème...\n",
    "* MMD\n",
    "    * Avec \"Inverse Multiquadratics\" kernel, cf. WAE 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recherche pour publication début 2021, spécifique sur l'interpolation de paramètres\n",
    "\n",
    "Se focaliser sur l'entraînement et la généralisation à tout synthé - pour interpolation de presets.\n",
    "\n",
    "* *Structure de base : WAE avec enc/dec à CNN sur spectrogramme ?*\n",
    "    * *(on pourrait aussi essayer le temporal encoder wavenet)*\n",
    "* Extension du taf de Esling et al. 2019/2020 \n",
    "    * Résultats très encourageants, mais il y a clairement *room for improvement*\n",
    "        * Nb de params du synthé : limités\n",
    "        * À tester sur d'autres synthés, comme le DX7 (synthèse + complexe mais pas d'effets intégrés)\n",
    "    * Dans l'objectif de l'interp. de preset\n",
    "        * **Étude de continuité sonore de l'interpolation ?**\n",
    "        * Pour n'importe quel synth, avec peu de presets, zéro meta-tag\n",
    "        * Pure unsupervised learning\n",
    "        * **Étude applicative, en explorant différents synthés et différents spectrogrammes ?**\n",
    "            * *Avantage de faire ça : peu importe que ça ne marche pas bien avec un synthé ou l'autre...*\n",
    "    * **Tests de fonctions de Loss pondérées sur spectrogr**\n",
    "        * Facteur de loss + important sur les basses fréquences (Mel-Loss)\n",
    "        * Facteur de loss + important à proximité de l'attaque et du release\n",
    "    * Leurs résultats comparaient déjà les 2 approches intéressantes\n",
    "        * **Flow inversible z <-> v, qui est la solution idéale pour l'interpolation**\n",
    "            * Mais FlowSynth sans Flow : 2-layer MLP 1024 n'est pas très profond (d'où : - expressif que Flow)\n",
    "        * WAE avec MLP z -> v ??\n",
    "            * MLP régression sauvage\n",
    "            * MLP avec modélisation fine (sortie cat. vs sorties gaussiennes)\n",
    "        * **Tester d'autres NN inversibles ?** Sans forcément modéliser toutes les maths...?\n",
    "            * Le domaine des INN, c'est un peu le domaine des flows...\n",
    "    * Autre expé avec le DX7, avec comme objectifs\n",
    "        * Confirmer ou infirmer résultats, pour un autre synthé\n",
    "            * En utilisant *tous* les paramètres du synthé, pas un subset choisi (max 64 sur 200+ dans Diva)\n",
    "            * **Problème du pitch/vel qui influe --> entraîner un NN AVEC PITCH ET VEL DANS LE VAE ?? Il faudrait plusieurs spectrogrammes pour 1 seule estimation**\n",
    "        * Essayer d'améliorer la modélisation de l'audio avec NNs plus gros\n",
    "        * Tester **data augmentation** en modifiant légèrement certaines valeurs de paramètres avant de générer en live un spectrogramme\n",
    "            * Essayer un synthé avec beaucoup moins de preset. En pratique, on a rarement 10000 ou 30000 presets (et qualité discutable) comme avec diva et/ou le DX7.\n",
    "            * Problèmes en multi-processing (deadlock dans selector.py) avec RenderMan ? Pas sûr : PIP avait le même blocage. **Ré-essayer le rendu audio temps-réel**\n",
    "        * Discuter des avantages/inconvénients du MLP z->v vs. flow z<->v\n",
    "    * GAN - AutoEncoder ?\n",
    "        * Voir s'il existe une structure pour ça, déjà...\n",
    "        * Ça ferait un double Loss, mais peut-être meilleur que MSE\n",
    "        \n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-encoder audio seul\n",
    "\n",
    "## Visualisation des tailles de tenseur entrée/sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Architecture = speccnn8l1\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─SpectrogramCNN: 1-1                    [256, 1024, 3, 4]         --\n",
      "|    └─Sequential: 2-1                   [256, 1024, 3, 4]         --\n",
      "|    |    └─Conv2D: 3-1                  [256, 8, 129, 174]        --\n",
      "|    |    |    └─Conv2d: 4-1             [256, 8, 129, 174]        208\n",
      "|    |    |    └─LeakyReLU: 4-2          [256, 8, 129, 174]        --\n",
      "|    |    |    └─BatchNorm2d: 4-3        [256, 8, 129, 174]        16\n",
      "|    |    └─Conv2D: 3-2                  [256, 16, 65, 88]         --\n",
      "|    |    |    └─Conv2d: 4-4             [256, 16, 65, 88]         2,064\n",
      "|    |    |    └─LeakyReLU: 4-5          [256, 16, 65, 88]         --\n",
      "|    |    |    └─BatchNorm2d: 4-6        [256, 16, 65, 88]         32\n",
      "|    |    └─Conv2D: 3-3                  [256, 32, 33, 45]         --\n",
      "|    |    |    └─Conv2d: 4-7             [256, 32, 33, 45]         8,224\n",
      "|    |    |    └─LeakyReLU: 4-8          [256, 32, 33, 45]         --\n",
      "|    |    |    └─BatchNorm2d: 4-9        [256, 32, 33, 45]         64\n",
      "|    |    └─Conv2D: 3-4                  [256, 64, 17, 23]         --\n",
      "|    |    |    └─Conv2d: 4-10            [256, 64, 17, 23]         32,832\n",
      "|    |    |    └─LeakyReLU: 4-11         [256, 64, 17, 23]         --\n",
      "|    |    |    └─BatchNorm2d: 4-12       [256, 64, 17, 23]         128\n",
      "|    |    └─Conv2D: 3-5                  [256, 128, 9, 12]         --\n",
      "|    |    |    └─Conv2d: 4-13            [256, 128, 9, 12]         131,200\n",
      "|    |    |    └─LeakyReLU: 4-14         [256, 128, 9, 12]         --\n",
      "|    |    |    └─BatchNorm2d: 4-15       [256, 128, 9, 12]         256\n",
      "|    |    └─Conv2D: 3-6                  [256, 256, 5, 7]          --\n",
      "|    |    |    └─Conv2d: 4-16            [256, 256, 5, 7]          524,544\n",
      "|    |    |    └─LeakyReLU: 4-17         [256, 256, 5, 7]          --\n",
      "|    |    |    └─BatchNorm2d: 4-18       [256, 256, 5, 7]          512\n",
      "|    |    └─Conv2D: 3-7                  [256, 512, 3, 4]          --\n",
      "|    |    |    └─Conv2d: 4-19            [256, 512, 3, 4]          2,097,664\n",
      "|    |    |    └─LeakyReLU: 4-20         [256, 512, 3, 4]          --\n",
      "|    |    |    └─BatchNorm2d: 4-21       [256, 512, 3, 4]          1,024\n",
      "|    |    └─Conv2D: 3-8                  [256, 1024, 3, 4]         --\n",
      "|    |    |    └─Conv2d: 4-22            [256, 1024, 3, 4]         525,312\n",
      "|    |    |    └─LeakyReLU: 4-23         [256, 1024, 3, 4]         --\n",
      "|    |    |    └─BatchNorm2d: 4-24       [256, 1024, 3, 4]         2,048\n",
      "├─Sequential: 1-2                        [256, 512]                --\n",
      "|    └─Linear: 2-2                       [256, 512]                6,291,968\n",
      "|    └─Dropout: 2-3                      [256, 512]                --\n",
      "==========================================================================================\n",
      "Total params: 9,618,096\n",
      "Trainable params: 9,618,096\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 127.70\n",
      "==========================================================================================\n",
      "Input size (MB): 91.32\n",
      "Forward/backward pass size (MB): 1577.39\n",
      "Params size (MB): 38.47\n",
      "Estimated Total Size (MB): 1707.18\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import importlib\n",
    "\n",
    "import torchinfo\n",
    "from model import encoder\n",
    "from model import decoder\n",
    "import model.layer\n",
    "from model import VAE\n",
    "import config\n",
    "\n",
    "def reload_all_modules():\n",
    "    importlib.reload(encoder)\n",
    "    importlib.reload(decoder)\n",
    "    importlib.reload(model.layer)\n",
    "    importlib.reload(model.VAE)\n",
    "    importlib.reload(config)\n",
    "    # ---------- Forced architecture choice ----------\n",
    "    config.model.encoder_architecture = 'speccnn8l1'\n",
    "    config.train.minibatch_size = 256  # forced minibatch size (for fair ram/ops comparisons)\n",
    "    config.model.input_tensor_size = (config.train.minibatch_size, 1, config.model.spectrogram_size[0], config.model.spectrogram_size[1])\n",
    "reload_all_modules()\n",
    "\n",
    "# - - - Copié depuis train.py - - -\n",
    "encoder_model = encoder.SpectrogramEncoder(config.model.encoder_architecture, config.model.dim_z,\n",
    "                                           config.model.spectrogram_size, config.train.fc_dropout)\n",
    "# - - - fin de copie - - -\n",
    "print(\"Encoder Architecture = {}\".format(config.model.encoder_architecture))\n",
    "_ = torchinfo.summary(encoder_model, input_size=config.model.input_tensor_size, depth=5, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Architecture = speccnn8l1\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─Sequential: 1-1                             [256, 12288]              --\n",
      "|    └─Linear: 2-1                            [256, 12288]              3,158,016\n",
      "|    └─Dropout: 2-2                           [256, 12288]              --\n",
      "├─SpectrogramCNN: 1-2                         [256, 1, 257, 347]        --\n",
      "|    └─Sequential: 2-3                        [256, 1, 257, 347]        --\n",
      "|    |    └─TConv2D: 3-1                      [256, 512, 3, 4]          --\n",
      "|    |    |    └─ConvTranspose2d: 4-1         [256, 512, 3, 4]          524,800\n",
      "|    |    |    └─LeakyReLU: 4-2               [256, 512, 3, 4]          --\n",
      "|    |    |    └─BatchNorm2d: 4-3             [256, 512, 3, 4]          1,024\n",
      "|    |    └─TConv2D: 3-2                      [256, 256, 5, 7]          --\n",
      "|    |    |    └─ConvTranspose2d: 4-4         [256, 256, 5, 7]          2,097,408\n",
      "|    |    |    └─LeakyReLU: 4-5               [256, 256, 5, 7]          --\n",
      "|    |    |    └─BatchNorm2d: 4-6             [256, 256, 5, 7]          512\n",
      "|    |    └─TConv2D: 3-3                      [256, 128, 9, 12]         --\n",
      "|    |    |    └─ConvTranspose2d: 4-7         [256, 128, 9, 12]         524,416\n",
      "|    |    |    └─LeakyReLU: 4-8               [256, 128, 9, 12]         --\n",
      "|    |    |    └─BatchNorm2d: 4-9             [256, 128, 9, 12]         256\n",
      "|    |    └─TConv2D: 3-4                      [256, 64, 17, 23]         --\n",
      "|    |    |    └─ConvTranspose2d: 4-10        [256, 64, 17, 23]         131,136\n",
      "|    |    |    └─LeakyReLU: 4-11              [256, 64, 17, 23]         --\n",
      "|    |    |    └─BatchNorm2d: 4-12            [256, 64, 17, 23]         128\n",
      "|    |    └─TConv2D: 3-5                      [256, 32, 33, 45]         --\n",
      "|    |    |    └─ConvTranspose2d: 4-13        [256, 32, 33, 45]         32,800\n",
      "|    |    |    └─LeakyReLU: 4-14              [256, 32, 33, 45]         --\n",
      "|    |    |    └─BatchNorm2d: 4-15            [256, 32, 33, 45]         64\n",
      "|    |    └─TConv2D: 3-6                      [256, 16, 65, 88]         --\n",
      "|    |    |    └─ConvTranspose2d: 4-16        [256, 16, 65, 88]         8,208\n",
      "|    |    |    └─LeakyReLU: 4-17              [256, 16, 65, 88]         --\n",
      "|    |    |    └─BatchNorm2d: 4-18            [256, 16, 65, 88]         32\n",
      "|    |    └─TConv2D: 3-7                      [256, 8, 129, 174]        --\n",
      "|    |    |    └─ConvTranspose2d: 4-19        [256, 8, 129, 174]        2,056\n",
      "|    |    |    └─LeakyReLU: 4-20              [256, 8, 129, 174]        --\n",
      "|    |    |    └─BatchNorm2d: 4-21            [256, 8, 129, 174]        16\n",
      "|    |    └─ConvTranspose2d: 3-8              [256, 1, 257, 347]        201\n",
      "|    |    └─Tanh: 3-9                         [256, 1, 257, 347]        --\n",
      "===============================================================================================\n",
      "Total params: 6,481,073\n",
      "Trainable params: 6,481,073\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 363.14\n",
      "===============================================================================================\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 1733.81\n",
      "Params size (MB): 25.92\n",
      "Estimated Total Size (MB): 1760.00\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary on the DECODER alone\n",
    "reload_all_modules()\n",
    "# - - - Copié depuis train.py - - -\n",
    "decoder_model = decoder.SpectrogramDecoder(config.model.encoder_architecture, config.model.dim_z,\n",
    "                                           config.model.spectrogram_size, config.train.fc_dropout)\n",
    "# - - - fin de copie - - -\n",
    "print(\"Decoder Architecture = {}\".format(config.model.encoder_architecture))  # Same as encoder\n",
    "_ = torchinfo.summary(decoder_model, input_size=(config.train.minibatch_size, config.model.dim_z), depth=5, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "├─SpectrogramEncoder: 1-1                          [256, 2, 256]             --\n",
      "|    └─SpectrogramCNN: 2-1                         [256, 1024, 3, 4]         --\n",
      "|    |    └─Sequential: 3-1                        [256, 1024, 3, 4]         --\n",
      "|    |    |    └─Conv2D: 4-1                       [256, 8, 129, 174]        --\n",
      "|    |    |    |    └─Conv2d: 5-1                  [256, 8, 129, 174]        208\n",
      "|    |    |    |    └─LeakyReLU: 5-2               [256, 8, 129, 174]        --\n",
      "|    |    |    |    └─BatchNorm2d: 5-3             [256, 8, 129, 174]        16\n",
      "|    |    |    └─Conv2D: 4-2                       [256, 16, 65, 88]         --\n",
      "|    |    |    |    └─Conv2d: 5-4                  [256, 16, 65, 88]         2,064\n",
      "|    |    |    |    └─LeakyReLU: 5-5               [256, 16, 65, 88]         --\n",
      "|    |    |    |    └─BatchNorm2d: 5-6             [256, 16, 65, 88]         32\n",
      "|    |    |    └─Conv2D: 4-3                       [256, 32, 33, 45]         --\n",
      "|    |    |    |    └─Conv2d: 5-7                  [256, 32, 33, 45]         8,224\n",
      "|    |    |    |    └─LeakyReLU: 5-8               [256, 32, 33, 45]         --\n",
      "|    |    |    |    └─BatchNorm2d: 5-9             [256, 32, 33, 45]         64\n",
      "|    |    |    └─Conv2D: 4-4                       [256, 64, 17, 23]         --\n",
      "|    |    |    |    └─Conv2d: 5-10                 [256, 64, 17, 23]         32,832\n",
      "|    |    |    |    └─LeakyReLU: 5-11              [256, 64, 17, 23]         --\n",
      "|    |    |    |    └─BatchNorm2d: 5-12            [256, 64, 17, 23]         128\n",
      "|    |    |    └─Conv2D: 4-5                       [256, 128, 9, 12]         --\n",
      "|    |    |    |    └─Conv2d: 5-13                 [256, 128, 9, 12]         131,200\n",
      "|    |    |    |    └─LeakyReLU: 5-14              [256, 128, 9, 12]         --\n",
      "|    |    |    |    └─BatchNorm2d: 5-15            [256, 128, 9, 12]         256\n",
      "|    |    |    └─Conv2D: 4-6                       [256, 256, 5, 7]          --\n",
      "|    |    |    |    └─Conv2d: 5-16                 [256, 256, 5, 7]          524,544\n",
      "|    |    |    |    └─LeakyReLU: 5-17              [256, 256, 5, 7]          --\n",
      "|    |    |    |    └─BatchNorm2d: 5-18            [256, 256, 5, 7]          512\n",
      "|    |    |    └─Conv2D: 4-7                       [256, 512, 3, 4]          --\n",
      "|    |    |    |    └─Conv2d: 5-19                 [256, 512, 3, 4]          2,097,664\n",
      "|    |    |    |    └─LeakyReLU: 5-20              [256, 512, 3, 4]          --\n",
      "|    |    |    |    └─BatchNorm2d: 5-21            [256, 512, 3, 4]          1,024\n",
      "|    |    |    └─Conv2D: 4-8                       [256, 1024, 3, 4]         --\n",
      "|    |    |    |    └─Conv2d: 5-22                 [256, 1024, 3, 4]         525,312\n",
      "|    |    |    |    └─LeakyReLU: 5-23              [256, 1024, 3, 4]         --\n",
      "|    |    |    |    └─BatchNorm2d: 5-24            [256, 1024, 3, 4]         2,048\n",
      "|    └─Sequential: 2-2                             [256, 512]                --\n",
      "|    |    └─Linear: 3-2                            [256, 512]                6,291,968\n",
      "|    |    └─Dropout: 3-3                           [256, 512]                --\n",
      "├─SpectrogramDecoder: 1-2                          [256, 1, 257, 347]        --\n",
      "|    └─Sequential: 2-3                             [256, 12288]              --\n",
      "|    |    └─Linear: 3-4                            [256, 12288]              3,158,016\n",
      "|    |    └─Dropout: 3-5                           [256, 12288]              --\n",
      "|    └─SpectrogramCNN: 2-4                         [256, 1, 257, 347]        --\n",
      "|    |    └─Sequential: 3-6                        [256, 1, 257, 347]        --\n",
      "|    |    |    └─TConv2D: 4-9                      [256, 512, 3, 4]          --\n",
      "|    |    |    |    └─ConvTranspose2d: 5-25        [256, 512, 3, 4]          524,800\n",
      "|    |    |    |    └─LeakyReLU: 5-26              [256, 512, 3, 4]          --\n",
      "|    |    |    |    └─BatchNorm2d: 5-27            [256, 512, 3, 4]          1,024\n",
      "|    |    |    └─TConv2D: 4-10                     [256, 256, 5, 7]          --\n",
      "|    |    |    |    └─ConvTranspose2d: 5-28        [256, 256, 5, 7]          2,097,408\n",
      "|    |    |    |    └─LeakyReLU: 5-29              [256, 256, 5, 7]          --\n",
      "|    |    |    |    └─BatchNorm2d: 5-30            [256, 256, 5, 7]          512\n",
      "|    |    |    └─TConv2D: 4-11                     [256, 128, 9, 12]         --\n",
      "|    |    |    |    └─ConvTranspose2d: 5-31        [256, 128, 9, 12]         524,416\n",
      "|    |    |    |    └─LeakyReLU: 5-32              [256, 128, 9, 12]         --\n",
      "|    |    |    |    └─BatchNorm2d: 5-33            [256, 128, 9, 12]         256\n",
      "|    |    |    └─TConv2D: 4-12                     [256, 64, 17, 23]         --\n",
      "|    |    |    |    └─ConvTranspose2d: 5-34        [256, 64, 17, 23]         131,136\n",
      "|    |    |    |    └─LeakyReLU: 5-35              [256, 64, 17, 23]         --\n",
      "|    |    |    |    └─BatchNorm2d: 5-36            [256, 64, 17, 23]         128\n",
      "|    |    |    └─TConv2D: 4-13                     [256, 32, 33, 45]         --\n",
      "|    |    |    |    └─ConvTranspose2d: 5-37        [256, 32, 33, 45]         32,800\n",
      "|    |    |    |    └─LeakyReLU: 5-38              [256, 32, 33, 45]         --\n",
      "|    |    |    |    └─BatchNorm2d: 5-39            [256, 32, 33, 45]         64\n",
      "|    |    |    └─TConv2D: 4-14                     [256, 16, 65, 88]         --\n",
      "|    |    |    |    └─ConvTranspose2d: 5-40        [256, 16, 65, 88]         8,208\n",
      "|    |    |    |    └─LeakyReLU: 5-41              [256, 16, 65, 88]         --\n",
      "|    |    |    |    └─BatchNorm2d: 5-42            [256, 16, 65, 88]         32\n",
      "|    |    |    └─TConv2D: 4-15                     [256, 8, 129, 174]        --\n",
      "|    |    |    |    └─ConvTranspose2d: 5-43        [256, 8, 129, 174]        2,056\n",
      "|    |    |    |    └─LeakyReLU: 5-44              [256, 8, 129, 174]        --\n",
      "|    |    |    |    └─BatchNorm2d: 5-45            [256, 8, 129, 174]        16\n",
      "|    |    |    └─ConvTranspose2d: 4-16             [256, 1, 257, 347]        201\n",
      "|    |    |    └─Tanh: 4-17                        [256, 1, 257, 347]        --\n",
      "====================================================================================================\n",
      "Total params: 16,099,169\n",
      "Trainable params: 16,099,169\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 506.92\n",
      "====================================================================================================\n",
      "Input size (MB): 91.32\n",
      "Forward/backward pass size (MB): 3311.20\n",
      "Params size (MB): 64.40\n",
      "Estimated Total Size (MB): 3466.91\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Full-model summary\n",
    "reload_all_modules()\n",
    "# - - - Copié depuis train.py - - -\n",
    "ae_model = VAE.BasicVAE(encoder_model, config.model.dim_z, decoder_model)\n",
    "# - - - fin de copie - - -\n",
    "_ = torchinfo.summary(ae_model, input_size=config.model.input_tensor_size, depth=5, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "# Évaluation des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/gwendal/Jupyter/nn-synth-interp/saved/SpecVAE1/07-3_NEW_BASE/config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a4decebd6320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mroot_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/gwendal/Jupyter/nn-synth-interp/saved/SpecVAE1/07-3_NEW_BASE/config.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Jupyter/nn-synth-interp/utils/config.py\u001b[0m in \u001b[0;36mget_config_from_file\u001b[0;34m(absolute_file_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \"\"\" Returns the model_config and train_config from a config.json saved run file,\n\u001b[1;32m     18\u001b[0m     which contains the same values as the original config.py file that was used during trainin. \"\"\"\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabsolute_file_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mconfig_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# All lists (default json parse) must be converted to tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/gwendal/Jupyter/nn-synth-interp/saved/SpecVAE1/07-3_NEW_BASE/config.json'"
     ]
    }
   ],
   "source": [
    "# TEMP TEST load \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "from IPython.display import Audio\n",
    "\n",
    "import model.build\n",
    "import logs.logger\n",
    "importlib.reload(logs.logger)\n",
    "import utils.config\n",
    "importlib.reload(utils.config)\n",
    "\n",
    "root_path = Path(os.getcwd())\n",
    "model_config, train_config = utils.config.get_config_from_file(\"/home/gwendal/Jupyter/nn-synth-interp/saved/SpecVAE1/07-3_NEW_BASE/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = logs.logger.get_model_last_checkpoint(root_path, model_config)\n",
    "_, _, ae_model = model.build.build_ae_model(model_config, train_config)\n",
    "ae_model.load_state_dict(checkpoint['ae_model_state_dict'])  # loaded on GPU\n",
    "ae_model = ae_model.cpu()\n",
    "_ = ae_model.eval()\n",
    "# TODO Consistency check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data.dataset\n",
    "importlib.reload(data.dataset)\n",
    "import data.build\n",
    "\n",
    "# Copied from train.py  FIXME - USE LOADED CONFIG \n",
    "full_dataset, dataset = data.build.get_full_and_split_datasets(config.model, config.train)\n",
    "dataloader = data.build.get_split_dataloaders(config.train, full_dataset, dataset)\n",
    "config.model.synth_params_count = full_dataset.learnable_params_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio reconstruction\n",
    "* De-normalize spectrograms\n",
    "* dB to linear amplitude\n",
    "* (inverse Mel spectrogram transform)\n",
    "* Get STFT phase from original audio\n",
    "* G&L phase reconstruction\n",
    "* ISTFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "import librosa.display\n",
    "import utils.audio\n",
    "importlib.reload(utils.audio)\n",
    "\n",
    "cmap = 'magma'\n",
    "\n",
    "# TODO audio reconstruction - build methods in utils.audio module\n",
    "dataset_idx = 12\n",
    "with torch.no_grad():\n",
    "    x_in, params_in, sample_info, labels = dataset['validation'][dataset_idx]  # single-spectrogram only\n",
    "    x_out = ae_model(x_in.unsqueeze(0))[2].detach().squeeze(0)  # single-spectrogram only\n",
    "preset_UID = sample_info[0]\n",
    "\n",
    "x_wav, Fs = full_dataset._get_wav_file(preset_UID)\n",
    "if full_dataset.n_mel_bins <= 0:\n",
    "    original_spec = full_dataset.spectrogram.get_stft(x_wav).numpy()\n",
    "else:\n",
    "    original_spec = full_dataset.spectrogram.log_to_linear_scale(full_dataset.denormalize_spectrogram(x_in[0])).numpy()\n",
    "original_spec_normalized = x_in[0].numpy()\n",
    "recons_spec_normalized = x_out[0].numpy()\n",
    "recons_spec_module = full_dataset.denormalize_spectrogram(x_out[0])\n",
    "recons_spec_module = full_dataset.spectrogram.log_to_linear_scale(recons_spec_module)\n",
    "if full_dataset.n_mel_bins > 0:\n",
    "    stft_before_mel = full_dataset.spectrogram.get_stft(x_wav).numpy()\n",
    "    recons_stft_module = full_dataset.spectrogram.mel_dB_to_STFT(full_dataset.denormalize_spectrogram(x_out[0]))\n",
    "\n",
    "if full_dataset.n_mel_bins <= 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(8, 6))\n",
    "else:\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(8, 9))\n",
    "im = librosa.display.specshow(np.abs(original_spec), ax=axes[0][0], cmap=cmap)\n",
    "clb = fig.colorbar(im, ax=axes[0][0], orientation='vertical')\n",
    "clb.ax.set_title('|stft|' if full_dataset.n_mel_bins <= 0 else '|mel|')\n",
    "axes[0][0].set(title='Original')\n",
    "im = librosa.display.specshow(original_spec_normalized, ax=axes[1][0], cmap=cmap)\n",
    "clb = fig.colorbar(im, ax=axes[1][0], orientation='vertical')\n",
    "clb.ax.set_title('dB,norm')\n",
    "im = librosa.display.specshow(recons_spec_normalized, ax=axes[1][1], cmap=cmap)\n",
    "clb = fig.colorbar(im, ax=axes[1][1], orientation='vertical')\n",
    "clb.ax.set_title('dB,norm')\n",
    "im = librosa.display.specshow(recons_spec_module.numpy(), ax=axes[0][1], cmap=cmap)\n",
    "clb = fig.colorbar(im, ax=axes[0][1], orientation='vertical')\n",
    "clb.ax.set_title('|stft|' if full_dataset.n_mel_bins <= 0 else '|mel|')\n",
    "axes[0][1].set(title='Reconstructed')\n",
    "fig.tight_layout()\n",
    "\n",
    "# si on a un mel-spectrogramme\n",
    "if full_dataset.n_mel_bins > 0:\n",
    "    im = librosa.display.specshow(np.abs(stft_before_mel), ax=axes[2][0], cmap=cmap)\n",
    "    clb = fig.colorbar(im, ax=axes[2][0], orientation='vertical')\n",
    "    axes[2][0].set(title=\"STFT\")\n",
    "    im = librosa.display.specshow(np.abs(recons_stft_module), ax=axes[2][1], cmap=cmap)\n",
    "    clb = fig.colorbar(im, ax=axes[2][1], orientation='vertical')\n",
    "    axes[2][1].set(title=\"estimated STFT\")\n",
    "\n",
    "\n",
    "print(\"Preset UID={} original audio:\".format(preset_UID))\n",
    "Audio(x_wav, rate=Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STFT phase of original audio - spectogram is possibly mel-scaled\n",
    "if full_dataset.n_mel_bins <= 0:\n",
    "    recons_stft = recons_spec_module.numpy() * np.exp(1j * np.angle(original_spec))\n",
    "    # G&L and ISTFT\n",
    "    # FFT size extracted from stft size. Default window: Hann. Phase init: use provided phase\n",
    "    x_wav_recons = librosa.griffinlim(recons_stft, init=None, hop_length=full_dataset.fft_hop)\n",
    "else:  # Mel\n",
    "    recons_stft = recons_stft_module * np.exp(1j * np.angle(stft_before_mel))\n",
    "    x_wav_recons = librosa.griffinlim(recons_stft, init=None, hop_length=full_dataset.fft_hop)\n",
    "\n",
    "print(\"Reconstructed audio (preset UID={})\".format(preset_UID))\n",
    "Audio(x_wav_recons, rate=Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent Space Entanglement: see all results in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
