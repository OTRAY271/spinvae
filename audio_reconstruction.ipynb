{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Reconstruction - auto encoders\n",
    "\n",
    "Avant de passer à la régression de paramètres de synthé, on va d'abord entraîner un AE à reconstruire les (mel-spectrogrammes) des sons des presets du DX7.\n",
    "\n",
    "Choix du AE :\n",
    "* Encodeur/décodeur à CNN sur spectrogramme (FlowSynth, IRCAM 2019)\n",
    "    * WAE, qui d'après (Esling et al. 2020) donne au final les meilleures régressions de paramètres de synthé ?\n",
    "    * Divers VAE avec flow, qui d'après (Esling et al. 2020) donnent la meilleure reconstruction audio ? (avec metadata....)\n",
    "* WaveNet\n",
    "    * Temporal encoder à convolution sur raw audio\n",
    "        * Comparer le *baseline CNN encoder* avec le *temporal encoder* sur spectrogrammes ? Même si Google Brain/DeepMind restent sur du CNN classique \n",
    "    * Décodeur WaveNet : beaucoup trop lourd\n",
    "\n",
    "Questions en suspens :\n",
    "* Comment implémenter la régularisation MMD du WAE ?\n",
    "    * Avec \"Inverse Multiquadratics\" kernel, cf. WAE 2018\n",
    "* VAE avec normalizing flow : est-ce qu'on fait la régularisation au début ou à la fin du flow ?\n",
    "    * Pour WAE : même problème...\n",
    "* Intégrer le pitch qqpart va sans doute beaucoup aider\n",
    "    * Pour comprendre tous les params, plusieurs notes//plusieurs pitch sont probablement nécessaires\n",
    "\n",
    "Dimension de l'espace latent z :\n",
    "* FlowSynth (Esling et al. 2020) prend $d_z = d_v$ avec $v$ le vecteur des paramètres. En effet, ils ont voulu un flow inversible entre z et v\n",
    "    * $+$ : traduction facile d'un preset en vecteur latent z\n",
    "    * $+$ : de chaque côté de l'interpolation, on a *exactement* le preset d'origine...\n",
    "    * $-$ : limite de taille de l'espace latent\n",
    "    * $-$ : MSE assez forte sur valeurs de paramètres (flow inversible pas si puissant qu'un NN)\n",
    "* WaveNet AE (Engel et al. 2017) encode un z à 2 dimensions : 16 dimensions par timestep, 125 timesteps de 512 samples (32 ms à 16kHz)\n",
    "    * Un latent z comme ça permet sans doute de bien représenter attaque/sustain/decay, LFO, etc ? Et donc d'obtenir une bonne reconstruction\n",
    "\n",
    "\n",
    "Recherche pour publication début 2021, spécifique sur l'interpolation de paramètres\n",
    "* Structure de base : WAE avec enc/dec à CNN sur spectrogramme\n",
    "    * *(on pourrait aussi essayer le temporal encoder wavenet)*\n",
    "* Comparaison de l'extraction des valeurs de paramètres :\n",
    "    * Flow inversible z <-> v\n",
    "    * MLP z -> v (mais reconstruction doit être excellente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mel-Spectrogram\n",
    "\n",
    "Quelques écoutes pour avoir une idée de la taille des spectrogrammes en E/S. Reconstruction audio par G&L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
