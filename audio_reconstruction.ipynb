{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Reconstruction - auto encoders\n",
    "\n",
    "## Architecture générale : CNN ?\n",
    "\n",
    "Avant de passer à la régression de paramètres de synthé, on va d'abord entraîner un AE à reconstruire les (mel-spectrogrammes) des sons des presets du DX7.\n",
    "\n",
    "Choix du AE :\n",
    "* Encodeur/décodeur à CNN sur spectrogramme (FlowSynth, IRCAM 2019)\n",
    "    * Encodeur (décodeur idem) : 5 couches de 64 canaux, kernel 7, stride 2, dilation 2\n",
    "    * WAE, qui d'après (Esling et al. 2020) donne au final les meilleures régressions de paramètres de synthé ?\n",
    "    * Divers VAE avec flow, qui d'après (Esling et al. 2020) donnent la meilleure reconstruction audio ? (avec metadata....)\n",
    "        * (https://acids-ircam.github.io/flow_synthesizer/#models-details)\n",
    "* WaveNet\n",
    "    * 10 couches de kernel 4, stride 2, dilation 1. Nombre de canaux va de 128-512 à 1024 pour mix final\n",
    "    * Temporal encoder à convolution sur raw audio\n",
    "        * Comparer le *baseline CNN encoder* avec le *temporal encoder* sur spectrogrammes ? Même si Google Brain/DeepMind restent sur du CNN classique \n",
    "    * Décodeur WaveNet : beaucoup trop lourd\n",
    "* WaveNet baseline (and temporal) :\n",
    "![](https://pbs.twimg.com/media/C8spAMCXYAAX6ml.jpg)\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions en suspens :\n",
    "* Est-ce c'est intéressant d'avoir un décodeur qui génère une image légèrement trop large ? (Pour limiter les effets de bords sur les dernières couches)\n",
    "* Comment implémenter la régularisation MMD du WAE ?\n",
    "    * Avec \"Inverse Multiquadratics\" kernel, cf. WAE 2018\n",
    "* VAE avec normalizing flow : est-ce qu'on fait la régularisation au début ou à la fin du flow ?\n",
    "    * Pour WAE : même problème...\n",
    "* Intégrer le pitch qqpart va sans doute beaucoup aider\n",
    "    * Pour comprendre tous les params, plusieurs notes//plusieurs pitch sont probablement nécessaires\n",
    "* Problème général des synthés qui peuvent générer le même son de plusieurs manières différentes\n",
    "\n",
    "## Dimension de l'espace latent z :\n",
    "* FlowSynth (Esling et al. 2020) prend $d_z = d_v$ avec $v$ le vecteur des paramètres. En effet, ils ont voulu un flow inversible entre z et v\n",
    "    * $+$ : traduction facile d'un preset en vecteur latent z\n",
    "    * $+$ : de chaque côté de l'interpolation, on a *exactement* le preset d'origine...\n",
    "    * $+$ : chaque réel $z_i$ peut se rapprocher d'une dimension perceptuelle de haut-niveau\n",
    "    * $-$ : limite de taille de l'espace latent\n",
    "    * $-$ : autant de \"macro-contrôles\" que de params de synthé (solution possible : interp miem...)\n",
    "    * $-$ : MSE assez forte sur valeurs de paramètres (flow inversible pas si puissant qu'un NN)\n",
    "* WaveNet AE (Engel et al. 2017) encode un z à 2 dimensions : 16 dimensions par timestep, 125 timesteps de 512 samples (32 ms à 16kHz)\n",
    "    * Un latent z comme ça permet sans doute de bien représenter attaque/sustain/decay, LFO, etc ? Et donc d'obtenir une bonne reconstruction\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss\n",
    "\n",
    "### Coût de reconstruction\n",
    "* MSE Loss\n",
    "* Spectral convergence ?\n",
    "\n",
    "### Régularisation\n",
    "* D_KL\n",
    "* MMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recherche pour publication début 2021, spécifique sur l'interpolation de paramètres\n",
    "\n",
    "Se focaliser sur l'entraînement et la généralisation à tout synthé - pour interpolation de presets.\n",
    "\n",
    "* *Structure de base : WAE avec enc/dec à CNN sur spectrogramme ?*\n",
    "    * *(on pourrait aussi essayer le temporal encoder wavenet)*\n",
    "* Extension du taf de Esling et al. 2019/2020 \n",
    "    * Résultats très encourageants, mais il y a clairement *room for improvement*\n",
    "        * Nb de params du synthé : limités\n",
    "        * À tester sur d'autres synthés, comme le DX7 (synthèse + complexe mais pas d'effets intégrés)\n",
    "    * Dans l'objectif de l'interp. de preset\n",
    "        * **Étude de continuité sonore de l'interpolation ?**\n",
    "        * Pour n'importe quel synth, avec peu de presets, zéro meta-tag\n",
    "        * Pure unsupervised learning\n",
    "        * **Étude applicative, en explorant différents synthés et différents spectrogrammes ?**\n",
    "            * *Avantage de faire ça : peu importe que ça ne marche pas bien avec un synthé ou l'autre...*\n",
    "    * **Tests de fonctions de Loss pondérées sur spectrogr**\n",
    "        * Facteur de loss + important sur les basses fréquences (Mel-Loss)\n",
    "        * Facteur de loss + important à proximité de l'attaque et du release\n",
    "    * Leurs résultats comparaient déjà les 2 approches intéressantes\n",
    "        * **Flow inversible z <-> v, qui est la solution idéale pour l'interpolation**\n",
    "            * Mais FlowSynth sans Flow : 2-layer MLP 1024 n'est pas très profond (d'où : - expressif que Flow)\n",
    "        * WAE avec MLP z -> v ??\n",
    "            * MLP régression sauvage\n",
    "            * MLP avec modélisation fine (sortie cat. vs sorties gaussiennes)\n",
    "        * **Tester d'autres NN inversibles ?** Sans forcément modéliser toutes les maths...?\n",
    "            * Le domaine des INN, c'est un peu le domaine des flows...\n",
    "    * Autre expé avec le DX7, avec comme objectifs\n",
    "        * Confirmer ou infirmer résultats, pour un autre synthé\n",
    "            * En utilisant *tous* les paramètres du synthé, pas un subset choisi (max 64 sur 200+ dans Diva)\n",
    "            * **Problème du pitch/vel qui influe --> entraîner un NN AVEC PITCH ET VEL DANS LE VAE ?? Il faudrait plusieurs spectrogrammes pour 1 seule estimation**\n",
    "        * Essayer d'améliorer la modélisation de l'audio avec NNs plus gros\n",
    "        * Tester **data augmentation** en modifiant légèrement certaines valeurs de paramètres avant de générer en live un spectrogramme\n",
    "            * Essayer un synthé avec beaucoup moins de preset. En pratique, on a rarement 10000 ou 30000 presets (et qualité discutable) comme avec diva et/ou le DX7.\n",
    "            * Problèmes en multi-processing (deadlock dans selector.py) avec RenderMan ? Pas sûr : PIP avait le même blocage. **Ré-essayer le rendu audio temps-réel**\n",
    "        * Discuter des avantages/inconvénients du MLP z->v vs. flow z<->v\n",
    "    * GAN - AutoEncoder ?\n",
    "        * Voir s'il existe une structure pour ça, déjà...\n",
    "        * Ça ferait un double Loss, mais peut-être meilleur que MSE\n",
    "        \n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-encoder audio seul\n",
    "\n",
    "## Visualisation des tailles de tenseur entrée/sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwendal/anaconda3/lib/python3.8/site-packages/torchaudio/backend/utils.py:53: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from data import dataset\n",
    "import importlib\n",
    "importlib.reload(dataset)\n",
    "\n",
    "dexed_dataset = dataset.DexedDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Architecture = speccnn8l1\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─SpectrogramCNN: 1-1                    [192, 1024, 3, 4]         --\n",
      "|    └─Sequential: 2-1                   [192, 1024, 3, 4]         --\n",
      "|    |    └─Conv2D: 3-1                  [192, 8, 129, 174]        --\n",
      "|    |    |    └─Conv2d: 4-1             [192, 8, 129, 174]        208\n",
      "|    |    |    └─LeakyReLU: 4-2          [192, 8, 129, 174]        --\n",
      "|    |    |    └─BatchNorm2d: 4-3        [192, 8, 129, 174]        16\n",
      "|    |    └─Conv2D: 3-2                  [192, 16, 65, 88]         --\n",
      "|    |    |    └─Conv2d: 4-4             [192, 16, 65, 88]         2,064\n",
      "|    |    |    └─LeakyReLU: 4-5          [192, 16, 65, 88]         --\n",
      "|    |    |    └─BatchNorm2d: 4-6        [192, 16, 65, 88]         32\n",
      "|    |    └─Conv2D: 3-3                  [192, 32, 33, 45]         --\n",
      "|    |    |    └─Conv2d: 4-7             [192, 32, 33, 45]         8,224\n",
      "|    |    |    └─LeakyReLU: 4-8          [192, 32, 33, 45]         --\n",
      "|    |    |    └─BatchNorm2d: 4-9        [192, 32, 33, 45]         64\n",
      "|    |    └─Conv2D: 3-4                  [192, 64, 17, 23]         --\n",
      "|    |    |    └─Conv2d: 4-10            [192, 64, 17, 23]         32,832\n",
      "|    |    |    └─LeakyReLU: 4-11         [192, 64, 17, 23]         --\n",
      "|    |    |    └─BatchNorm2d: 4-12       [192, 64, 17, 23]         128\n",
      "|    |    └─Conv2D: 3-5                  [192, 128, 9, 12]         --\n",
      "|    |    |    └─Conv2d: 4-13            [192, 128, 9, 12]         131,200\n",
      "|    |    |    └─LeakyReLU: 4-14         [192, 128, 9, 12]         --\n",
      "|    |    |    └─BatchNorm2d: 4-15       [192, 128, 9, 12]         256\n",
      "|    |    └─Conv2D: 3-6                  [192, 256, 5, 7]          --\n",
      "|    |    |    └─Conv2d: 4-16            [192, 256, 5, 7]          524,544\n",
      "|    |    |    └─LeakyReLU: 4-17         [192, 256, 5, 7]          --\n",
      "|    |    |    └─BatchNorm2d: 4-18       [192, 256, 5, 7]          512\n",
      "|    |    └─Conv2D: 3-7                  [192, 512, 3, 4]          --\n",
      "|    |    |    └─Conv2d: 4-19            [192, 512, 3, 4]          2,097,664\n",
      "|    |    |    └─LeakyReLU: 4-20         [192, 512, 3, 4]          --\n",
      "|    |    |    └─BatchNorm2d: 4-21       [192, 512, 3, 4]          1,024\n",
      "|    |    └─Conv2D: 3-8                  [192, 1024, 3, 4]         --\n",
      "|    |    |    └─Conv2d: 4-22            [192, 1024, 3, 4]         525,312\n",
      "|    |    |    └─LeakyReLU: 4-23         [192, 1024, 3, 4]         --\n",
      "|    |    |    └─BatchNorm2d: 4-24       [192, 1024, 3, 4]         2,048\n",
      "├─Linear: 1-2                            [192, 512]                6,291,968\n",
      "==========================================================================================\n",
      "Total params: 9,618,096\n",
      "Trainable params: 9,618,096\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 121.40\n",
      "==========================================================================================\n",
      "Input size (MB): 68.49\n",
      "Forward/backward pass size (MB): 1183.04\n",
      "Params size (MB): 38.47\n",
      "Estimated Total Size (MB): 1290.00\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import importlib\n",
    "\n",
    "import torchinfo\n",
    "from model import encoder\n",
    "from model import decoder\n",
    "import model.layer\n",
    "from model import VAE\n",
    "import config\n",
    "\n",
    "def reload_all_modules():\n",
    "    importlib.reload(encoder)\n",
    "    importlib.reload(decoder)\n",
    "    importlib.reload(model.layer)\n",
    "    importlib.reload(model.VAE)\n",
    "    importlib.reload(config)\n",
    "reload_all_modules()\n",
    "\n",
    "# - - - Copié depuis train.py - - -\n",
    "encoder_model = encoder.SpectrogramEncoder(config.model.encoder_architecture, config.model.dim_z,\n",
    "                                           config.model.spectrogram_size)\n",
    "# - - - fin de copie - - -\n",
    "print(\"Encoder Architecture = {}\".format(config.model.encoder_architecture))\n",
    "_ = torchinfo.summary(encoder_model, input_size=config.model.input_tensor_size, depth=5, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Architecture = speccnn8l1\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─Linear: 1-1                                 [1, 12288]                3,158,016\n",
      "├─SpectrogramCNN: 1-2                         [1, 1, 257, 347]          --\n",
      "|    └─Sequential: 2-1                        [1, 1, 257, 347]          --\n",
      "|    |    └─TConv2D: 3-1                      [1, 512, 3, 4]            --\n",
      "|    |    |    └─ConvTranspose2d: 4-1         [1, 512, 3, 4]            524,800\n",
      "|    |    |    └─LeakyReLU: 4-2               [1, 512, 3, 4]            --\n",
      "|    |    |    └─BatchNorm2d: 4-3             [1, 512, 3, 4]            1,024\n",
      "|    |    └─TConv2D: 3-2                      [1, 256, 5, 7]            --\n",
      "|    |    |    └─ConvTranspose2d: 4-4         [1, 256, 5, 7]            2,097,408\n",
      "|    |    |    └─LeakyReLU: 4-5               [1, 256, 5, 7]            --\n",
      "|    |    |    └─BatchNorm2d: 4-6             [1, 256, 5, 7]            512\n",
      "|    |    └─TConv2D: 3-3                      [1, 128, 9, 12]           --\n",
      "|    |    |    └─ConvTranspose2d: 4-7         [1, 128, 9, 12]           524,416\n",
      "|    |    |    └─LeakyReLU: 4-8               [1, 128, 9, 12]           --\n",
      "|    |    |    └─BatchNorm2d: 4-9             [1, 128, 9, 12]           256\n",
      "|    |    └─TConv2D: 3-4                      [1, 64, 17, 23]           --\n",
      "|    |    |    └─ConvTranspose2d: 4-10        [1, 64, 17, 23]           131,136\n",
      "|    |    |    └─LeakyReLU: 4-11              [1, 64, 17, 23]           --\n",
      "|    |    |    └─BatchNorm2d: 4-12            [1, 64, 17, 23]           128\n",
      "|    |    └─TConv2D: 3-5                      [1, 32, 33, 45]           --\n",
      "|    |    |    └─ConvTranspose2d: 4-13        [1, 32, 33, 45]           32,800\n",
      "|    |    |    └─LeakyReLU: 4-14              [1, 32, 33, 45]           --\n",
      "|    |    |    └─BatchNorm2d: 4-15            [1, 32, 33, 45]           64\n",
      "|    |    └─TConv2D: 3-6                      [1, 16, 65, 88]           --\n",
      "|    |    |    └─ConvTranspose2d: 4-16        [1, 16, 65, 88]           8,208\n",
      "|    |    |    └─LeakyReLU: 4-17              [1, 16, 65, 88]           --\n",
      "|    |    |    └─BatchNorm2d: 4-18            [1, 16, 65, 88]           32\n",
      "|    |    └─TConv2D: 3-7                      [1, 8, 129, 174]          --\n",
      "|    |    |    └─ConvTranspose2d: 4-19        [1, 8, 129, 174]          2,056\n",
      "|    |    |    └─LeakyReLU: 4-20              [1, 8, 129, 174]          --\n",
      "|    |    |    └─BatchNorm2d: 4-21            [1, 8, 129, 174]          16\n",
      "|    |    └─ConvTranspose2d: 3-8              [1, 1, 257, 347]          201\n",
      "===============================================================================================\n",
      "Total params: 6,481,073\n",
      "Trainable params: 6,481,073\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 360.00\n",
      "===============================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 6.77\n",
      "Params size (MB): 25.92\n",
      "Estimated Total Size (MB): 32.70\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary on the DECODER alone\n",
    "reload_all_modules()\n",
    "# - - - Copié depuis train.py - - -\n",
    "decoder_model = decoder.SpectrogramDecoder(config.model.encoder_architecture, config.model.dim_z,\n",
    "                                           config.model.spectrogram_size)\n",
    "# - - - fin de copie - - -\n",
    "print(\"Decoder Architecture = {}\".format(config.model.encoder_architecture))  # Same as encoder\n",
    "_ = torchinfo.summary(decoder_model, input_size=(1, config.model.dim_z), depth=5, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "├─SpectrogramEncoder: 1-1                          [32, 2, 256]              --\n",
      "|    └─SpectrogramCNN: 2-1                         [32, 1024, 5, 5]          --\n",
      "|    |    └─Sequential: 3-1                        [32, 1024, 5, 5]          --\n",
      "|    |    |    └─Conv2D: 4-1                       [32, 8, 257, 217]         --\n",
      "|    |    |    |    └─Conv2d: 5-1                  [32, 8, 257, 217]         208\n",
      "|    |    |    |    └─LeakyReLU: 5-2               [32, 8, 257, 217]         --\n",
      "|    |    |    |    └─BatchNorm2d: 5-3             [32, 8, 257, 217]         16\n",
      "|    |    |    └─Conv2D: 4-2                       [32, 16, 129, 109]        --\n",
      "|    |    |    |    └─Conv2d: 5-4                  [32, 16, 129, 109]        2,064\n",
      "|    |    |    |    └─LeakyReLU: 5-5               [32, 16, 129, 109]        --\n",
      "|    |    |    |    └─BatchNorm2d: 5-6             [32, 16, 129, 109]        32\n",
      "|    |    |    └─Conv2D: 4-3                       [32, 32, 65, 55]          --\n",
      "|    |    |    |    └─Conv2d: 5-7                  [32, 32, 65, 55]          8,224\n",
      "|    |    |    |    └─LeakyReLU: 5-8               [32, 32, 65, 55]          --\n",
      "|    |    |    |    └─BatchNorm2d: 5-9             [32, 32, 65, 55]          64\n",
      "|    |    |    └─Conv2D: 4-4                       [32, 64, 33, 28]          --\n",
      "|    |    |    |    └─Conv2d: 5-10                 [32, 64, 33, 28]          32,832\n",
      "|    |    |    |    └─LeakyReLU: 5-11              [32, 64, 33, 28]          --\n",
      "|    |    |    |    └─BatchNorm2d: 5-12            [32, 64, 33, 28]          128\n",
      "|    |    |    └─Conv2D: 4-5                       [32, 128, 17, 15]         --\n",
      "|    |    |    |    └─Conv2d: 5-13                 [32, 128, 17, 15]         131,200\n",
      "|    |    |    |    └─LeakyReLU: 5-14              [32, 128, 17, 15]         --\n",
      "|    |    |    |    └─BatchNorm2d: 5-15            [32, 128, 17, 15]         256\n",
      "|    |    |    └─Conv2D: 4-6                       [32, 256, 9, 8]           --\n",
      "|    |    |    |    └─Conv2d: 5-16                 [32, 256, 9, 8]           524,544\n",
      "|    |    |    |    └─LeakyReLU: 5-17              [32, 256, 9, 8]           --\n",
      "|    |    |    |    └─BatchNorm2d: 5-18            [32, 256, 9, 8]           512\n",
      "|    |    |    └─Conv2D: 4-7                       [32, 512, 5, 5]           --\n",
      "|    |    |    |    └─Conv2d: 5-19                 [32, 512, 5, 5]           2,097,664\n",
      "|    |    |    |    └─LeakyReLU: 5-20              [32, 512, 5, 5]           --\n",
      "|    |    |    |    └─BatchNorm2d: 5-21            [32, 512, 5, 5]           1,024\n",
      "|    |    |    └─Conv2D: 4-8                       [32, 1024, 5, 5]          --\n",
      "|    |    |    |    └─Conv2d: 5-22                 [32, 1024, 5, 5]          525,312\n",
      "|    |    |    |    └─LeakyReLU: 5-23              [32, 1024, 5, 5]          --\n",
      "|    |    |    |    └─BatchNorm2d: 5-24            [32, 1024, 5, 5]          2,048\n",
      "|    └─Linear: 2-2                                 [32, 512]                 13,107,712\n",
      "├─SpectrogramDecoder: 1-2                          [32, 1, 515, 419]         --\n",
      "|    └─Sequential: 2-3                             [32, 15232]               --\n",
      "|    |    └─Linear: 3-2                            [32, 1024]                263,168\n",
      "|    |    └─ReLU: 3-3                              [32, 1024]                --\n",
      "|    |    └─Linear: 3-4                            [32, 1024]                1,049,600\n",
      "|    |    └─ReLU: 3-5                              [32, 1024]                --\n",
      "|    |    └─Linear: 3-6                            [32, 15232]               15,612,800\n",
      "|    └─SpectrogramCNN: 2-4                         [32, 1, 515, 419]         --\n",
      "|    |    └─Sequential: 3-7                        [32, 1, 515, 419]         --\n",
      "|    |    |    └─TConv2D: 4-9                      [32, 64, 33, 27]          --\n",
      "|    |    |    |    └─ConvTranspose2d: 5-25        [32, 64, 33, 27]          200,768\n",
      "|    |    |    |    └─ELU: 5-26                    [32, 64, 33, 27]          --\n",
      "|    |    |    |    └─BatchNorm2d: 5-27            [32, 64, 33, 27]          128\n",
      "|    |    |    └─TConv2D: 4-10                     [32, 64, 65, 53]          --\n",
      "|    |    |    |    └─ConvTranspose2d: 5-28        [32, 64, 65, 53]          200,768\n",
      "|    |    |    |    └─ELU: 5-29                    [32, 64, 65, 53]          --\n",
      "|    |    |    |    └─BatchNorm2d: 5-30            [32, 64, 65, 53]          128\n",
      "|    |    |    └─TConv2D: 4-11                     [32, 64, 129, 105]        --\n",
      "|    |    |    |    └─ConvTranspose2d: 5-31        [32, 64, 129, 105]        200,768\n",
      "|    |    |    |    └─ELU: 5-32                    [32, 64, 129, 105]        --\n",
      "|    |    |    |    └─BatchNorm2d: 5-33            [32, 64, 129, 105]        128\n",
      "|    |    |    └─TConv2D: 4-12                     [32, 64, 257, 209]        --\n",
      "|    |    |    |    └─ConvTranspose2d: 5-34        [32, 64, 257, 209]        200,768\n",
      "|    |    |    |    └─ELU: 5-35                    [32, 64, 257, 209]        --\n",
      "|    |    |    |    └─BatchNorm2d: 5-36            [32, 64, 257, 209]        128\n",
      "|    |    |    └─TConv2D: 4-13                     [32, 1, 515, 419]         --\n",
      "|    |    |    |    └─ConvTranspose2d: 5-37        [32, 1, 515, 419]         3,137\n",
      "|    |    |    |    └─ELU: 5-38                    [32, 1, 515, 419]         --\n",
      "|    |    |    |    └─BatchNorm2d: 5-39            [32, 1, 515, 419]         2\n",
      "====================================================================================================\n",
      "Total params: 34,166,131\n",
      "Trainable params: 34,166,131\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 15.38\n",
      "====================================================================================================\n",
      "Input size (MB): 28.43\n",
      "Forward/backward pass size (MB): 2939.31\n",
      "Params size (MB): 136.66\n",
      "Estimated Total Size (MB): 3104.40\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Full-model summary\n",
    "reload_all_modules()\n",
    "# - - - Copié depuis train.py - - -\n",
    "ae_model = VAE.BasicVAE(encoder_model, config.model.dim_z, decoder_model)\n",
    "# - - - fin de copie - - -\n",
    "_ = torchinfo.summary(ae_model, input_size=config.model.input_tensor_size, depth=5, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
