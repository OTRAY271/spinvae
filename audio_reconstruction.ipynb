{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Reconstruction - auto encoders\n",
    "\n",
    "Avant de passer à la régression de paramètres de synthé, on va d'abord entraîner un AE à reconstruire les (mel-spectrogrammes) des sons des presets du DX7.\n",
    "\n",
    "Choix du AE :\n",
    "* Encodeur/décodeur à CNN sur spectrogramme (FlowSynth, IRCAM 2019)\n",
    "    * WAE, qui d'après (Esling et al. 2020) donne au final les meilleures régressions de paramètres de synthé ?\n",
    "    * Divers VAE avec flow, qui d'après (Esling et al. 2020) donnent la meilleure reconstruction audio ? (avec metadata....)\n",
    "* WaveNet\n",
    "    * Temporal encoder à convolution sur raw audio\n",
    "        * Comparer le *baseline CNN encoder* avec le *temporal encoder* sur spectrogrammes ? Même si Google Brain/DeepMind restent sur du CNN classique \n",
    "    * Décodeur WaveNet : beaucoup trop lourd\n",
    "\n",
    "Questions en suspens :\n",
    "* Comment implémenter la régularisation MMD du WAE ?\n",
    "    * Avec \"Inverse Multiquadratics\" kernel, cf. WAE 2018\n",
    "* VAE avec normalizing flow : est-ce qu'on fait la régularisation au début ou à la fin du flow ?\n",
    "    * Pour WAE : même problème...\n",
    "* Intégrer le pitch qqpart va sans doute beaucoup aider\n",
    "    * Pour comprendre tous les params, plusieurs notes//plusieurs pitch sont probablement nécessaires\n",
    "* Problème général des synthés qui peuvent générer le même son de plusieurs manières différentes\n",
    "\n",
    "Dimension de l'espace latent z :\n",
    "* FlowSynth (Esling et al. 2020) prend $d_z = d_v$ avec $v$ le vecteur des paramètres. En effet, ils ont voulu un flow inversible entre z et v\n",
    "    * $+$ : traduction facile d'un preset en vecteur latent z\n",
    "    * $+$ : de chaque côté de l'interpolation, on a *exactement* le preset d'origine...\n",
    "    * $+$ : chaque réel $z_i$ peut se rapprocher d'une dimension perceptuelle de haut-niveau\n",
    "    * $-$ : limite de taille de l'espace latent\n",
    "    * $-$ : autant de \"macro-contrôles\" que de params de synthé (solution possible : interp miem...)\n",
    "    * $-$ : MSE assez forte sur valeurs de paramètres (flow inversible pas si puissant qu'un NN)\n",
    "* WaveNet AE (Engel et al. 2017) encode un z à 2 dimensions : 16 dimensions par timestep, 125 timesteps de 512 samples (32 ms à 16kHz)\n",
    "    * Un latent z comme ça permet sans doute de bien représenter attaque/sustain/decay, LFO, etc ? Et donc d'obtenir une bonne reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recherche pour publication début 2021, spécifique sur l'interpolation de paramètres\n",
    "\n",
    "Se focaliser sur l'entraînement et la généralisation à tout synthé - pour interpolation de presets.\n",
    "\n",
    "* *Structure de base : WAE avec enc/dec à CNN sur spectrogramme ?*\n",
    "    * *(on pourrait aussi essayer le temporal encoder wavenet)*\n",
    "* Extension du taf de Esling et al. 2019/2020 \n",
    "    * Résultats très encourageants, mais il y a clairement *room for improvement*\n",
    "        * Nb de params du synthé : limités\n",
    "        * À tester sur d'autres synthés, comme le DX7 (synthèse + complexe mais pas d'effets intégrés)\n",
    "    * Dans l'objectif de l'interp. de preset\n",
    "        * **Étude de continuité sonore de l'interpolation ?**\n",
    "        * Pour n'importe quel synth, avec peu de presets, zéro meta-tag\n",
    "        * Pure unsupervised learning\n",
    "        * **Étude applicative, en explorant différents synthés et différents spectrogrammes ?**\n",
    "            * *Avantage de faire ça : peu importe que ça ne marche pas bien avec un synthé ou l'autre...*\n",
    "    * Leurs résultats comparaient déjà les 2 approches intéressantes\n",
    "        * **Flow inversible z <-> v, qui est la solution idéale pour l'interpolation**\n",
    "        * WAE avec MLP z -> v ??\n",
    "            * MLP régression sauvage\n",
    "            * MLP avec modélisation fine (sortie cat. vs sorties gaussiennes)\n",
    "        * **Tester d'autres NN inversibles ?** Sans forcément modéliser toutes les maths...?\n",
    "            * Le domaine des INN, c'est un peu le domaine des flows...\n",
    "    * Autre expé avec le DX7, avec comme objectifs\n",
    "        * Confirmer ou infirmer résultats, pour un autre synthé\n",
    "            * En utilisant *tous* les paramètres du synthé, pas un subset choisi (max 64 sur 200+ dans Diva)\n",
    "            * **Problème du pitch/vel qui influe --> entraîner un NN AVEC PITCH ET VEL DANS LE VAE ?? Il faudrait plusieurs spectrogrammes pour 1 seule estimation**\n",
    "        * Essayer d'améliorer la modélisation de l'audio avec NNs plus gros\n",
    "        * Tester **data augmentation** en modifiant légèrement certaines valeurs de paramètres avant de générer en live un spectrogramme\n",
    "            * Essayer un synthé avec beaucoup moins de preset. En pratique, on a rarement 10000 ou 30000 presets (et qualité discutable) comme avec diva et/ou le DX7.\n",
    "        * Discuter des avantages/inconvénients du MLP z->v vs. flow z<->v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
