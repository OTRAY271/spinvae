"""
Datasets of synth sounds.
Wav files can be re-generated by running this script as main - see end of file
"""

import os
import pathlib
from abc import ABC, abstractmethod  # Abstract Base Class
import pandas as pd
from multiprocessing import Lock
import time
import json
import itertools
import torch
import torch.nn as nn
import torch.utils
import soundfile
import numpy as np
import copy
import sys
import librosa

from synth import dexed
import utils.audio

# See https://github.com/pytorch/audio/issues/903
#torchaudio.set_audio_backend("sox_io")


# Global lock... Should be the same for all forked Unix processes
dexed_vst_lock = Lock()  # Unused - pre-rendered audio (at the moment)


def model_config_to_dataset_kwargs(model_config):
    """ Creates a dict that can be unpacked to pass to a PresetDataset class constructor.

    :param model_config: should be the config.model attribute from config.py. """
    return {'note_duration': model_config.note_duration, 'n_fft': model_config.stft_args[0],
            'fft_hop': model_config.stft_args[1], 'n_mel_bins': model_config.mel_bins,
            'spectrogram_min_dB': model_config.spectrogram_min_dB}


class PresetDataset(torch.utils.data.Dataset, ABC):
    def __init__(self, note_duration,
                 n_fft, fft_hop,  # ftt 1024 hop=512: spectrogram is approx. the size of 5.0s@22.05kHz audio
                 midi_note=60, midi_velocity=100,  # TODO default values - try others
                 n_mel_bins=-1, mel_fmin=30.0, mel_fmax=11e3,
                 normalize_audio=False, spectrogram_min_dB=-120.0, spectrogram_normalization='min_max'
                 ):
        """
        Abstract Base Class for any synthesizer presets dataset.

        :param note_duration: Tuple: MIDI Note (on_duration, off_duration) in seconds
        :param n_fft: Width of the FFT window for spectrogram computation
        :param fft_hop: STFT hop length (in samples)
        :param midi_note:  Default dataset MIDI note value (used to pre-render and to load .wav file)
        :param midi_velocity:  Default dataset MIDI velocity value (used to pre-render and to load .wav file)
        :param n_mel_bins: Number of frequency bins for the Mel-spectrogram. If -1, the normal STFT will be used
        :param mel_fmin: TODO implement
        :param mel_fmax: TODO implement
        :param normalize_audio:  If True, audio from RenderMan will be normalized
        :param spectrogram_min_dB:  Noise-floor threshold value for log-scale spectrograms
        :param spectrogram_normalization: 'min_max' to get output spectrogram values in [-1, 1], or 'mean_std'
            to get zero-mean unit-variance output spectrograms. None to disable normalization.
        """
        self.note_duration = note_duration
        self.n_fft = n_fft
        self.fft_hop = fft_hop
        self.midi_note = midi_note
        self.midi_velocity = midi_velocity
        self.n_mel_bins = n_mel_bins
        self.mel_fmin = mel_fmin
        self.mel_fmax = mel_fmax
        self.normalize_audio = normalize_audio
        # - - - - - Attributes to be set by the child concrete class - - - - -
        self.valid_preset_UIDs = np.zeros((0,))  # UIDs (may be indexes) of valid presets for this dataset
        self.learnable_params_idx = list()  # Indexes of learnable VSTi params (some params may be constant or unused)
        # - - - Spectrogram utility class - - -
        if self.n_mel_bins <= 0:
            self.spectrogram = utils.audio.Spectrogram(self.n_fft, self.fft_hop, spectrogram_min_dB)
        else:  # TODO do not hardcode Fs?
            self.spectrogram = utils.audio.MelSpectrogram(self.n_fft, self.fft_hop, spectrogram_min_dB,
                                                          self.n_mel_bins, 22050)
        # spectrogram min/max/mean/std statistics: must be loaded after super() ctor (depend on child class args)
        self.spectrogram_normalization = spectrogram_normalization
        self.spec_stats = None

    @property
    @abstractmethod
    def synth_name(self):
        pass

    def __str__(self):
        return "Dataset of {}/{} {} presets. {} learnable synth params, {} fixed params. " \
               "{} Spectrogram items, size={}, min={:.1f}dB, normalization:{}" \
            .format(len(self), self.total_nb_presets, self.synth_name, len(self.learnable_params_idx),
                    self.total_nb_params - len(self.learnable_params_idx),
                    ("Linear" if self.n_mel_bins <= 0 else "Mel"), self.get_spectrogram_tensor_size(),
                    self.spectrogram.min_dB, self.spectrogram_normalization)

    def __len__(self):  # Required for any torch.utils.data.Dataset
        return len(self.valid_preset_UIDs)

    def __getitem__(self, i):
        """ Returns a tuple containing a 2D scaled dB spectrogram tensor (1st dim: freq; 2nd dim: time),
        a 1D tensor of parameter values in [0;1], and a 1d tensor with remaining int info (preset UID, midi note, vel).

        If this dataset generates audio directly from the synth, only 1 dataloader is allowed.
        A 30000 presets dataset require approx. 7 minutes to be generated on 1 CPU. """
        # TODO on-the-fly audio generation. We should try:
        #  - Use shell command to run a dedicated script. The script writes AUDIO_SAMPLE_TEMP_ID.wav
        #  - wait for the file to be generated on disk (or for the command to notify... something)
        #  - read and delete this .wav file
        midi_note = self.midi_note
        midi_velocity = self.midi_velocity
        # loading params and wav file TODO load labels
        preset_UID = self.valid_preset_UIDs[i]
        preset_params = self.get_preset_params(preset_UID)
        # TODO multi-wav (multi MIDI note) loading
        x_wav, _ = self.get_wav_file(preset_UID, midi_note, midi_velocity)
        # Spectrogram, or Mel-Spectrogram if requested
        spectrogram = self.spectrogram(x_wav)
        if self.spectrogram_normalization == 'min_max':  # result in [-1, 1]
            spectrogram = -1.0 + (spectrogram - self.spec_stats['min'])\
                          / ((self.spec_stats['max'] - self.spec_stats['min']) / 2.0)
        elif self.spectrogram_normalization == 'mean_std':
            spectrogram = (spectrogram - self.spec_stats['mean']) / self.spec_stats['std']
        # Tuple output. Warning: torch.from_numpy does not copy values (torch.tensor(...) ctor does)
        # We add a first dimension to the spectrogram, which is a 1-ch 'greyscale' image
        # TODO multi-channel spectrograms with multiple MIDI notes (and velocities?)
        return torch.unsqueeze(spectrogram, 0), \
            torch.tensor(preset_params[self.learnable_params_idx], dtype=torch.float32), \
            torch.tensor([preset_UID, midi_note, midi_velocity], dtype=torch.int32), \
            self.get_labels_tensor(preset_UID)

    @property
    @abstractmethod
    def total_nb_presets(self):
        pass

    @abstractmethod
    def get_preset_params(self, preset_UID):
        """ Returns the list or numpy array of parameters for the requested preset_UID. Actual implementation
        depends on the synth (some params may be locked or unused). """
        pass

    @property
    @abstractmethod
    def preset_param_names(self):
        """ Returns a List which contains the name of all parameters of presets (free and constrained). """
        pass

    @property
    def learnable_params_count(self):
        """ Returns the length of the second tensor returned by this dataset. """
        return len(self.learnable_params_idx)

    @property
    @abstractmethod
    def total_nb_params(self):
        """ Returns the total count of constrained and free parameters of a preset. """
        pass

    def get_labels_tensor(self, preset_UID):
        """ Returns a tensor of torch.int8 zeros and ones - each value is 1 if the preset is tagged with the
        corresponding label """
        return torch.tensor([1], dtype=torch.int8)  # 'NoLabel' is the only default label

    def get_labels_name(self, preset_UID):
        """ Returns the list of string labels assigned to a preset """
        return ['NoLabel']  # Default: all presets are tagged with this dummy label. Implement in concrete class

    @property
    def available_labels_names(self):
        """ Returns a list of string description of labels. """
        return ['NoLabel']  # this dataset allows no label

    @property
    def labels_count(self):
        return len(self.available_labels_name)

    @abstractmethod
    def get_wav_file(self, preset_UID, midi_note, midi_velocity):
        pass

    def _get_wav_file(self, preset_UID):
        """ Returns the preset_UID audio (numpy array). MIDI note and velocity of the note are the class defaults. """
        # FIXME incompatible with future multi-MIDI notes input
        return self.get_wav_file(preset_UID, self.midi_note, self.midi_velocity)

    def _load_spectrogram_stats(self):
        """ To be called by the child class, after this parent class construction (because stats file path
        depends on child class constructor arguments). """
        try:
            f = open(self._get_spectrogram_stats_file(), 'r')
            self.spec_stats = json.load(f)
        except IOError:
            self.spec_stats = None
            self.spectrogram_normalization = None  # Normalization disabled
            print("[PresetDataset] Cannot open '{}' stats file.".format(self._get_spectrogram_stats_file()))
            print("[PresetDataset] No pre-computed spectrogram stats can be found. No normalization will be performed")

    def get_spectrogram_tensor_size(self):
        """ Returns the size of the first tensor (2D image) returned by this dataset. """
        dummy_spectrogram, _, _, _ = self.__getitem__(0)
        return dummy_spectrogram.size()

    @staticmethod
    def _get_spectrogram_stats_folder():
        """ Returns the path of a './stats' directory inside this script's directory """
        return pathlib.Path(__file__).parent.joinpath('stats')

    def _get_spectrogram_stats_file_stem(self):
        """ Returns the spectrogram stats file base name (without path, suffix and extension) """
        stem = '{}Dataset_spectrogram_nfft{:04d}hop{:04d}mels'.format(self.synth_name, self.n_fft, self.fft_hop)
        stem += ('None' if self.n_mel_bins <= 0 else '{:04d}'.format(self.n_mel_bins))
        return stem

    def _get_spectrogram_stats_file(self):
        return self._get_spectrogram_stats_folder().joinpath(self._get_spectrogram_stats_file_stem() + '.json')

    def _get_spectrogram_full_stats_file(self):
        return self._get_spectrogram_stats_folder().joinpath(self._get_spectrogram_stats_file_stem() + '_full.csv')

    def denormalize_spectrogram(self, spectrogram):
        if self.spectrogram_normalization == 'min_max':  # result in [-1, 1]
            # TODO check this for audio reconstruction
            return (spectrogram + 1.0) * ((self.spec_stats['max'] - self.spec_stats['min']) / 2.0)\
                   + self.spec_stats['min']
        elif self.spectrogram_normalization == 'mean_std':
            return spectrogram * self.spec_stats['std'] + self.spec_stats['mean']

    # TODO un-mel method
    def compute_and_store_spectrograms_stats(self):
        """ Compute min,max,mean,std on all presets previously rendered as wav files.
        Per-preset results are stored into a .csv file
        and dataset-wide averaged results are stored into a .json file

        This functions must be re-run when spectrogram parameters are changed. """
        full_stats = {'UID': [], 'min': [], 'max': [], 'mean': [], 'var': []}
        for i in range(len(self)):
            # We use the exact same spectrogram as the dataloader will
            # TODO multi-midi-notes spectrograms stats
            x_wav, Fs = self.get_wav_file(self.valid_preset_UIDs[i],
                                          self.midi_note, self.midi_velocity)
            assert Fs == 22050
            tensor_spectrogram = self.spectrogram(x_wav)
            full_stats['UID'].append(self.valid_preset_UIDs[i])
            full_stats['min'].append(torch.min(tensor_spectrogram).item())
            full_stats['max'].append(torch.max(tensor_spectrogram).item())
            full_stats['var'].append(torch.var(tensor_spectrogram).item())
            full_stats['mean'].append(torch.mean(tensor_spectrogram, dim=(0, 1)).item())
            if i % 5000 == 0:
                print("Processed stats of {}/{} spectrograms".format(i, len(self)))
        for key in full_stats:
            full_stats[key] = np.asarray(full_stats[key])
        # Average of all columns (std: sqrt(variance avg))
        dataset_stats = {'min': full_stats['min'].min(),
                         'max': full_stats['max'].max(),
                         'mean': full_stats['mean'].mean(),
                         'std': np.sqrt(full_stats['var'].mean()) }
        full_stats['std'] = np.sqrt(full_stats['var'])
        del full_stats['var']
        # Final output
        if not os.path.exists(self._get_spectrogram_stats_folder()):
            os.makedirs(self._get_spectrogram_stats_folder())
        full_stats = pd.DataFrame(full_stats)
        full_stats.to_csv(self._get_spectrogram_full_stats_file())
        with open(self._get_spectrogram_stats_file(), 'w') as f:
            json.dump(dataset_stats, f)
        print("Results written to {} _full.csv and .json files".format(self._get_spectrogram_stats_file_stem()))




class DexedDataset(PresetDataset):
    def __init__(self, note_duration, n_fft, fft_hop,
                 midi_note=60, midi_velocity=100,  # TODO default values - try others
                 n_mel_bins=-1, mel_fmin=30.0, mel_fmax=11e3,
                 normalize_audio=False, spectrogram_min_dB=-120.0, spectrogram_normalization='min_max',
                 algos=None, operators=None,
                 restrict_to_labels=None, constant_filter_and_tune_params=True, prevent_SH_LFO=True,
                 check_constrains_consistency=True
                 ):
        """
        Allows access to Dexed preset values and names, and generates spectrograms and corresponding
        parameters values. Can manage a reduced number of synth parameters (using default values for non-
        learnable params). Only Dexed-specific ctor args are described - see base PresetDataset class.

        It uses both the SQLite DB (through dexed.PresetDatabase) and the pre-written files extracted from
        the DB (see dexed.PresetDatabase.write_all_presets_to_files(...)).

        :param algos: List. Can be used to limit the DX7 algorithms included in this dataset. Set to None
            to use all available algorithms
        :param operators: List of ints, or None. Enables the specified operators only, or all of them if None.
        :param restrict_to_labels: List of strings. If not None, presets of this dataset will be selected such
            that they are tagged with at least one of the given labels.
        :param constant_filter_and_tune_params: if True, the main filter and the main tune settings are default
        :param prevent_SH_LFO: if True, replaces the SH random LFO by a square-wave deterministic LFO
        :param check_constrains_consistency: Set to False when this dataset instance is used to pre-render
            audio files
        """
        super().__init__(note_duration, n_fft, fft_hop, midi_note, midi_velocity, n_mel_bins, mel_fmin, mel_fmax,
                         normalize_audio, spectrogram_min_dB, spectrogram_normalization)
        self.prevent_SH_LFO = prevent_SH_LFO
        self.constant_filter_and_tune_params = constant_filter_and_tune_params
        if check_constrains_consistency:
            assert self.check_audio_render_constraints_file()  # pre-rendered audio constraints consistency
        self.algos = algos if algos is not None else []
        self._operators = operators if operators is not None else [1, 2, 3, 4, 5, 6]
        self.restrict_to_labels = restrict_to_labels
        # Full SQLite DB read and temp storage in np arrays
        dexed_db = dexed.PresetDatabase()
        self._total_nb_presets = dexed_db.presets_mat.shape[0]
        self._total_nb_params = dexed_db.presets_mat.shape[1]
        self._param_names = dexed_db.get_param_names()
        # - - - Constraints on parameters, learnable parameters - - -
        self.learnable_params_idx = list(range(0, dexed_db.presets_mat.shape[1]))
        if self.constant_filter_and_tune_params:  # (see dexed_db_explore.ipynb)
            for idx in [0, 1, 2, 3, 13]:
                self.learnable_params_idx.remove(idx)
        for i_op in range(6):  # Search for disabled operators
            if not (i_op+1) in self._operators:  # If disabled: we remove all corresponding learnable params
                for idx in range(21):  # Don't remove the 22nd param (OP on/off selector) yet
                    self.learnable_params_idx.remove(23 + 22*i_op + idx)  # idx 23 is the first param of op 1
        # All oscillators are always ON (see dexed db exploration notebook)
        # TODO this will change! to reduce the amount of learnable params
        # TODO add operators ctor arg
        for col in [44, 66, 88, 110, 132, 154]:
            self.learnable_params_idx.remove(col)
        # - - - Valid presets - UIDs of presets, and not their database row index - - -
        # Select valid presets by algorithm
        if len(self.algos) == 0:  # All presets are valid
            self.valid_preset_UIDs = dexed_db.all_presets_df["index_preset"].values
        else:
            if len(self.algos) == 1:
                self.learnable_params_idx.remove(4)  # Algo parameter column idx
            valid_presets_row_indexes = list()
            for algo in self.algos:
                valid_presets_row_indexes += dexed_db.get_preset_indexes_for_algorithm(algo)
            self.valid_preset_UIDs = dexed_db.all_presets_df\
                .iloc[valid_presets_row_indexes]['index_preset'].values
        # Select valid presets by label. We build a list of list-indexes to remove
        if self.restrict_to_labels is not None:
            self.valid_preset_UIDs = [uid for uid in self.valid_preset_UIDs
                                      if any([self.is_label_included(l) for l in self.get_labels_name(uid)])]
        # - - - DB class deleted (we need a low memory usage for multi-process dataloaders) - - -
        del dexed_db
        # - - - Final initializations - - -
        self._load_spectrogram_stats()  # Must be called after super() ctor

    @property
    def synth_name(self):  # Overrides parent abstract property
        return "Dexed"

    def __str__(self):  # Overrides parent method
        return "{}. Restricted to labels: {}. Enabled operators: {}".format(super().__str__(), self.restrict_to_labels,
                                                                            self._operators)

    @property
    def total_nb_presets(self):  # Overrides parent abstract property
        return self._total_nb_presets

    @property
    def total_nb_params(self):  # Overrides parent abstract property
        return self._total_nb_params

    @property
    def preset_param_names(self):  # Overrides parent abstract property
        return self._param_names

    def get_preset_params(self, preset_UID):  # Overrides parent abstract method
        """ Reads the requested preset params from a .pickle file and applies the constraints (constant values,
        non-learnable params) of this class.

        :returns: A full preset (including non-learnable controls) """
        preset_params = dexed.PresetDatabase.get_preset_params_values_from_file(preset_UID)
        return self._apply_preset_constraints(preset_params)

    def _apply_preset_constraints(self, preset_params):
        # General constraints (constant params)
        dexed.Dexed.set_all_oscillators_on_(preset_params)
        if self.constant_filter_and_tune_params:
            dexed.Dexed.set_default_general_filter_and_tune_params_(preset_params)
        if self.prevent_SH_LFO:
            dexed.Dexed.prevent_SH_LFO_(preset_params)
        # enable/disable operators
        for op_i in range(6):
            preset_params[44 + 22*op_i] = (1.0 if (op_i+1) in self._operators else 0.0)
        return preset_params

    def is_label_included(self, label):
        """ Returns True if the label belongs to the restricted labels list. """
        if self.restrict_to_labels is None:
            return True
        else:
            return any([label == l_ for l_ in self.restrict_to_labels])

    def get_labels_tensor(self, preset_UID):  # TODO Overrides parent abstract method
        """ Returns a tensor of torch.int8 zeros and ones - each value is 1 if the preset is tagged with the
        corresponding label """
        return torch.tensor([1], dtype=torch.int8)  # 'NoLabel' is the only default label

    def get_labels_name(self, preset_UID):  # Overrides parent abstract method
        return dexed.PresetDatabase.get_preset_labels_from_file(preset_UID)

    @property
    def available_labels_names(self):  # Overrides parent abstract method
        """ Returns a tuple of string description of labels. """
        return dexed.PresetDatabase.get_available_labels()

    def _render_audio(self, preset_params, midi_note, midi_velocity):
        """ Renders audio on-the-fly and returns the computed audio waveform and sampling rate.

        :param preset_params: Constrained preset parameters (constraints from this class ctor args must have
            been applied before passing preset_params).
        """
        # reload the VST to prevent hanging notes/sounds
        dexed_renderer = dexed.Dexed(midi_note_duration_s=self.note_duration[0],
                                     render_duration_s=self.note_duration[0] + self.note_duration[1])
        dexed_renderer.assign_preset(dexed.PresetDatabase.get_params_in_plugin_format(preset_params))
        x_wav = dexed_renderer.render_note(midi_note, midi_velocity, normalize=self.normalize_audio)
        return x_wav, dexed_renderer.Fs

    def fill_preset(self, learnable_preset_params):
        """ Given an incomplete vector of preset values (learnable controls only), returns the
        corresponding full-size preset (including non-learnable controls).
        General parameters (e.g. main filter and transpose) will be set to their default value, and
        non-learnable operator params (disabled operators) will be set to -0.1.

        :param learnable_preset_params: Incomplete preset (learned params only)
        """
        assert len(learnable_preset_params) == self.learnable_params_count
        preset_params = -0.1 * np.ones((self.total_nb_params,))  # TODO start from original preset
        preset_params[self.learnable_params_idx] = np.asarray(learnable_preset_params)
        return self._apply_preset_constraints(preset_params)

    def _get_spectrogram_stats_file_stem(self):  # Overrides parent method
        return super()._get_spectrogram_stats_file_stem() + self._operators_suffix

    @property
    def _operators_suffix(self):
        """ Returns a suffix (to be used in files names) that describes enabled DX7 operators, as configured
        in this dataset's constructor. Return an empty string if all operators are used. """
        ops_suffix = ''
        if self._operators != [1, 2, 3, 4, 5, 6]:
            ops_suffix = '_op' + ''.join(['{}'.format(op) for op in self._operators])
        return ops_suffix

    def get_wav_file_path(self, preset_UID, midi_note, midi_velocity):
        """ Returns the path of a wav (from dexed_presets folder). Operators"""
        presets_folder = dexed.PresetDatabase._get_presets_folder()
        filename = "preset{:06d}_midi{:03d}vel{:03d}{}.wav".format(preset_UID, midi_note, midi_velocity,
                                                                   self._operators_suffix)
        return presets_folder.joinpath(filename)

    def get_wav_file(self, preset_UID, midi_note, midi_velocity):  # Overrides parent abstract method
        file_path = self.get_wav_file_path(preset_UID, midi_note, midi_velocity)
        try:
            return soundfile.read(file_path)
        except RuntimeError:
            raise RuntimeError("[data/dataset.py] Can't open file {}. Please pre-render audio files for this "
                               "dataset configuration.".format(file_path))

    def generate_wav_files(self):
        """ Reads all presets (names, param values, and labels) from .pickle and .txt files
         (see dexed.PresetDatabase.write_all_presets_to_files(...)) and renders them
         using attributes and constraints of this class (midi note, normalization, etc...)

         Floating-point .wav files will be stored in dexed presets' folder (see synth/dexed.py)

         Also writes a audio_render_constraints.json file that should be checked when loading data.
         """
        # TODO multiple midi notes generation
        midi_note, midi_velocity = self.midi_note, self.midi_velocity
        for i in range(len(self)):   # TODO full dataset
            preset_UID = self.valid_preset_UIDs[i]
            preset_params = self.get_preset_params(preset_UID)  # Constrained params
            x_wav, Fs = self._render_audio(preset_params, midi_note, midi_velocity)  # Re-Loads the VST
            soundfile.write(self.get_wav_file_path(preset_UID, midi_note, midi_velocity),
                            x_wav, Fs, subtype='FLOAT')
            if i % 5000 == 0:
                print("Writing .wav files... ({}/{})".format(i, len(self)))
        self.write_audio_render_constraints_file()
        print("Finished writing {} .wav files".format(len(self)))

    def write_audio_render_constraints_file(self):
        file_path = dexed.PresetDatabase._get_presets_folder().joinpath("audio_render_constraints_file.json")
        with open(file_path, 'w') as f:
            json.dump({'constant_filter_and_tune_params': self.constant_filter_and_tune_params,
                       'prevent_SH_LFO': self.prevent_SH_LFO}, f)

    def check_audio_render_constraints_file(self):
        """ Returns True if the constraints used to pre-rendered audio are the same as this instance constraints
        (S&H locked, filter/tune general params, ...) """
        file_path = dexed.PresetDatabase._get_presets_folder().joinpath("audio_render_constraints_file.json")
        with open(file_path, 'r') as f:
            constraints = json.load(f)
            return constraints['constant_filter_and_tune_params'] == self.constant_filter_and_tune_params\
                and constraints['prevent_SH_LFO'] == self.prevent_SH_LFO




if __name__ == "__main__":

    # ============== DATA RE-GENERATION - FROM config.py ==================
    regenerate_wav = True  # quite long (15min, full dataset, 1 midi note)
    regenerate_spectrograms_stats = True  # approx 3 min

    import sys
    sys.path.append(pathlib.Path(__file__).parent.parent)
    import config  # Dirty path trick to import config.py from project root dir

    #operators = config.model.dataset_synth_args[1]  # Custom operators limitation?
    operators = [1, 2, 3, 4]

    # No label restriction, no normalization, etc...
    # But: OPERATORS LIMITATIONS and DEFAULT PARAM CONSTRAINTS (main params (filter, transpose,...) are constant)
    dexed_dataset = DexedDataset(note_duration=config.model.note_duration,
                                 n_fft=config.model.stft_args[0], fft_hop=config.model.stft_args[1],
                                 n_mel_bins=config.model.mel_bins,
                                 spectrogram_normalization=None,  # No normalization: we want to compute stats
                                 algos=None, restrict_to_labels=None,
                                 operators=operators,  # Operators limitation (config.py)
                                 spectrogram_min_dB=config.model.spectrogram_min_dB,
                                 check_constrains_consistency=False)
    #print(dexed_dataset)  # All files must be pre-rendered before printing

    if regenerate_wav:
        # WRITE ALL WAV FILES (approx. 10.5Go for 4.0s audio, 1 midi note)
        dexed_dataset.generate_wav_files()
    if regenerate_spectrograms_stats:
        # whole-dataset stats (for proper normalization)
        dexed_dataset.compute_and_store_spectrograms_stats()
    # ============== DATA RE-GENERATION - FROM config.py ==================



    # Dataloader debug tests
    if False:
        # Test dataload - to trigger potential errors
        # _, _, _ = dexed_dataset[0]

        dexed_dataloader = torch.utils.data.DataLoader(dexed_dataset, batch_size=128, shuffle=False,
                                                       num_workers=1)#os.cpu_count() * 9 // 10)
        t0 = time.time()
        for batch_idx, sample in enumerate(dexed_dataloader):
            print(batch_idx)
            print(sample)
            if batch_idx%10 == 0:
                print("batch {}".format(batch_idx))
        print("Full dataset read in {:.1f} minutes.".format((time.time() - t0) / 60.0))
