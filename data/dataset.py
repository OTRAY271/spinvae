"""
Datasets of synth sounds.
Wav files can be re-generated by running this script as main - see end of file
"""

import os
import pathlib
from abc import ABC, abstractmethod  # Abstract Base Class
import pandas as pd
from multiprocessing import Lock
import time
import json
import itertools
import torch
import torch.nn as nn
import torch.utils
import soundfile
import numpy as np
import copy
import sys
import librosa

from synth import dexed
import utils.audio

# See https://github.com/pytorch/audio/issues/903
#torchaudio.set_audio_backend("sox_io")


# Global lock... Should be the same for all forked Unix processes
dexed_vst_lock = Lock()  # Unused - pre-rendered audio (at the moment)


def model_config_to_dataset_kwargs(model_config):
    """ Creates a dict that can be unpacked to pass to a PresetDataset class constructor.

    :param model_config: should be the config.model attribute from config.py. """
    return {'note_duration': model_config.note_duration, 'n_fft': model_config.stft_args[0],
            'fft_hop': model_config.stft_args[1], 'n_mel_bins': model_config.mel_bins,
            'spectrogram_min_dB': model_config.spectrogram_min_dB}


class PresetDataset(torch.utils.data.Dataset, ABC):
    def __init__(self, note_duration,
                 n_fft, fft_hop,  # ftt 1024 hop=512: spectrogram is approx. the size of 5.0s@22.05kHz audio
                 midi_note=60, midi_velocity=100,  # TODO default values - try others
                 n_mel_bins=-1, mel_fmin=30.0, mel_fmax=11e3,
                 normalize_audio=False, spectrogram_min_dB=-120.0, spectrogram_normalization='min_max'
                 ):
        """
        Abstract Base Class for any synthesizer presets dataset.

        :param note_duration: Tuple: MIDI Note (on_duration, off_duration) in seconds
        :param n_fft: Width of the FFT window for spectrogram computation
        :param fft_hop: STFT hop length (in samples)
        :param midi_note:  Default dataset MIDI note value (used to pre-render and to load .wav file)
        :param midi_velocity:  Default dataset MIDI velocity value (used to pre-render and to load .wav file)
        :param n_mel_bins: Number of frequency bins for the Mel-spectrogram. If -1, the normal STFT will be used
        :param mel_fmin: TODO implement
        :param mel_fmax: TODO implement
        :param normalize_audio:  If True, audio from RenderMan will be normalized
        :param spectrogram_min_dB:  Noise-floor threshold value for log-scale spectrograms
        :param spectrogram_normalization: 'min_max' to get output spectrogram values in [-1, 1], or 'mean_std'
            to get zero-mean unit-variance output spectrograms. None to disable normalization.
        """
        self.note_duration = note_duration
        self.n_fft = n_fft
        self.fft_hop = fft_hop
        self.midi_note = midi_note
        self.midi_velocity = midi_velocity
        self.n_mel_bins = n_mel_bins
        self.mel_fmin = mel_fmin
        self.mel_fmax = mel_fmax
        self.normalize_audio = normalize_audio
        # - - - - - Attributes to be set by the child concrete class - - - - -
        self.valid_preset_UIDs = np.zeros((0,))  # UIDs (may be indexes) of valid presets for this dataset
        self.learnable_params_idx = list()  # Indexes of learnable VSTi params (some params may be constant or unused)
        # - - - Spectrogram utility class - - -
        if self.n_mel_bins <= 0:
            self.spectrogram = utils.audio.Spectrogram(self.n_fft, self.fft_hop, spectrogram_min_dB)
        else:  # TODO do not hardcode Fs?
            self.spectrogram = utils.audio.MelSpectrogram(self.n_fft, self.fft_hop, spectrogram_min_dB,
                                                          self.n_mel_bins, 22050)
        # try load spectrogram min/max/mean/std statistics
        self.spectrogram_normalization = spectrogram_normalization
        try:
            f = open(self._get_spectrogram_stats_file(), 'r')
            self.spec_stats = json.load(f)
        except IOError:
            self.spec_stats = None
            self.spectrogram_normalization = None  # Normalization disabled
            print("[PresetDataset] Cannot open '{}' stats file.".format(self._get_spectrogram_stats_file()))
            print("[PresetDataset] No pre-computed spectrogram stats can be found. No normalization will be performed")

    @property
    @abstractmethod
    def synth_name(self):
        pass

    def __str__(self):
        return "Dataset of {}/{} {} presets. {} learnable synth params, {} fixed params. " \
               "{} Spectrogram items, size={}, min={:.1f}dB, normalization:{}" \
            .format(len(self), self.total_nb_presets, self.synth_name, len(self.learnable_params_idx),
                    self.total_nb_params - len(self.learnable_params_idx),
                    ("Linear" if self.n_mel_bins <= 0 else "Mel"), self.get_spectrogram_tensor_size(),
                    self.spectrogram.min_dB, self.spectrogram_normalization)

    def __len__(self):  # Required for any torch.utils.data.Dataset
        return len(self.valid_preset_UIDs)

    def __getitem__(self, i):
        """ Returns a tuple containing a 2D scaled dB spectrogram tensor (1st dim: freq; 2nd dim: time),
        a 1D tensor of parameter values in [0;1], and a 1d tensor with remaining int info (preset UID, midi note, vel).

        If this dataset generates audio directly from the synth, only 1 dataloader is allowed.
        A 30000 presets dataset require approx. 7 minutes to be generated on 1 CPU. """
        # TODO on-the-fly audio generation. We should try:
        #  - Use shell command to run a dedicated script. The script writes AUDIO_SAMPLE_TEMP_ID.wav
        #  - wait for the file to be generated on disk (or for the command to notify... something)
        #  - read and delete this .wav file
        midi_note = self.midi_note
        midi_velocity = self.midi_velocity
        # loading params and wav file TODO load labels
        preset_UID = self.valid_preset_UIDs[i]
        preset_params = self.get_preset_params(preset_UID)
        x_wav, _ = self.get_wav_file(preset_UID, midi_note, midi_velocity)
        # Spectrogram, or Mel-Spectrogram if requested
        spectrogram = self.spectrogram(x_wav)
        if self.spectrogram_normalization == 'min_max':  # result in [-1, 1]
            spectrogram = -1.0 + (spectrogram - self.spec_stats['min'])\
                          / ((self.spec_stats['max'] - self.spec_stats['min']) / 2.0)
        elif self.spectrogram_normalization == 'mean_std':
            spectrogram = (spectrogram - self.spec_stats['mean']) / self.spec_stats['std']
        # TODO labels pytorch array
        # Tuple output. Warning: torch.from_numpy does not copy values
        # We add a first dimension to the spectrogram, which is a 1-ch 'greyscale' image
        return torch.unsqueeze(spectrogram, 0), \
            torch.tensor(preset_params[self.learnable_params_idx], dtype=torch.float32), \
            torch.tensor([preset_UID, midi_note, midi_velocity], dtype=torch.int32), \
            self.get_labels_tensor(preset_UID)

    @abstractmethod
    def get_preset_params(self, preset_UID):
        """ Returns the list or numpy array of parameters for the requested preset_UID. Actual implementation
        depends on the synth (some params may be locked or unused). """
        pass

    @property
    def learnable_params_count(self):
        """ Returns the length of the second tensor returned by this dataset. """
        return len(self.learnable_params_idx)

    def get_labels_tensor(self, preset_UID):
        """ Returns a tensor of torch.int8 zeros and ones - each value is 1 if the preset is tagged with the
        corresponding label """
        return torch.tensor([1], dtype=torch.int8)  # 'NoLabel' is the only default label

    def get_labels_name(self, preset_UID):
        """ Returns the list of string labels assigned to a preset """
        return ['NoLabel']  # Default: all presets are tagged with this dummy label. Implement in concrete class

    @property
    def available_labels_names(self):
        """ Returns a list of string description of labels. """
        return ['NoLabel']  # this dataset allows no label

    @property
    def labels_count(self):
        return len(self.available_labels_name)

    @staticmethod
    @abstractmethod
    def get_wav_file(preset_UID, midi_note, midi_velocity):
        pass

    def _get_wav_file(self, preset_UID):
        """ Returns the preset_UID audio (numpy array). MIDI note and velocity of the note are the class defaults. """
        return self.get_wav_file(preset_UID, self.midi_note, self.midi_velocity)

    def get_spectrogram_tensor_size(self):
        """ Returns the size of the first tensor (2D image) returned by this dataset. """
        dummy_spectrogram, _, _, _ = self.__getitem__(0)
        return dummy_spectrogram.size()

    @staticmethod
    def _get_spectrogram_stats_folder():
        """ Returns the path of a './stats' directory inside this script's directory """
        return pathlib.Path(__file__).parent.joinpath('stats')

    def _get_spectrogram_stats_file_stem(self):
        """ Returns the spectrogram stats file base name (without path, suffix and extension) """
        stem = '{}Dataset_spectrogram_nfft{:04d}hop{:04d}mels'.format(self.synth_name, self.n_fft, self.fft_hop)
        stem += ('None' if self.n_mel_bins <= 0 else '{:04d}'.format(self.n_mel_bins))
        return stem

    def _get_spectrogram_stats_file(self):
        return self._get_spectrogram_stats_folder().joinpath(self._get_spectrogram_stats_file_stem() + '.json')

    def _get_spectrogram_full_stats_file(self):
        return self._get_spectrogram_stats_folder().joinpath(self._get_spectrogram_stats_file_stem() + '_full.csv')

    def denormalize_spectrogram(self, spectrogram):
        if self.spectrogram_normalization == 'min_max':  # result in [-1, 1]
            # TODO check this for audio reconstruction
            return (spectrogram + 1.0) * ((self.spec_stats['max'] - self.spec_stats['min']) / 2.0)\
                   + self.spec_stats['min']
        elif self.spectrogram_normalization == 'mean_std':
            return spectrogram * self.spec_stats['std'] + self.spec_stats['mean']

    # TODO un-mel method
    def compute_and_store_spectrograms_stats(self):
        """ Compute min,max,mean,std on all presets previously rendered as wav files.
        Per-preset results are stored into a .csv file
        and dataset-wide averaged results are stored into a .json file

        This functions must be re-run when spectrogram parameters are changed. """
        full_stats = {'UID': [], 'min': [], 'max': [], 'mean': [], 'var': []}
        for i in range(len(self)):
            # We use the exact same spectrogram as the dataloader will
            x_wav, Fs = self.get_wav_file(self.valid_preset_UIDs[i],
                                          self.midi_note, self.midi_velocity)
            assert Fs == 22050
            tensor_spectrogram = self.spectrogram(x_wav)
            full_stats['UID'].append(self.valid_preset_UIDs[i])
            full_stats['min'].append(torch.min(tensor_spectrogram).item())
            full_stats['max'].append(torch.max(tensor_spectrogram).item())
            full_stats['var'].append(torch.var(tensor_spectrogram).item())
            full_stats['mean'].append(torch.mean(tensor_spectrogram, dim=(0, 1)).item())
            if i % 5000 == 0:
                print("Processed stats of {}/{} spectrograms".format(i, len(self)))
        for key in full_stats:
            full_stats[key] = np.asarray(full_stats[key])
        # Average of all columns (std: sqrt(variance avg))
        dataset_stats = {'min': full_stats['min'].min(),
                         'max': full_stats['max'].max(),
                         'mean': full_stats['mean'].mean(),
                         'std': np.sqrt(full_stats['var'].mean()) }
        full_stats['std'] = np.sqrt(full_stats['var'])
        del full_stats['var']
        # Final output
        if not os.path.exists(self._get_spectrogram_stats_folder()):
            os.makedirs(self._get_spectrogram_stats_folder())
        full_stats = pd.DataFrame(full_stats)
        full_stats.to_csv(self._get_spectrogram_full_stats_file())
        with open(self._get_spectrogram_stats_file(), 'w') as f:
            json.dump(dataset_stats, f)
        print("Results written to {} _full.csv and .json files".format(self._get_spectrogram_stats_file_stem()))




class DexedDataset(PresetDataset):
    def __init__(self, note_duration, n_fft, fft_hop,
                 midi_note=60, midi_velocity=100,  # TODO default values - try others
                 n_mel_bins=-1, mel_fmin=30.0, mel_fmax=11e3,
                 normalize_audio=False, spectrogram_min_dB=-120.0, spectrogram_normalization='min_max',
                 algos=None, restrict_to_labels=None, constant_filter_and_tune_params=True, prevent_SH_LFO=True,
                 check_constrains_consistency=True
                 ):
        """
        Allows access to Dexed preset values and names, and generates spectrograms and corresponding
        parameters values. Can manage a reduced number of synth parameters (using default values for non-
        learnable params). Only Dexed-specific ctor args are described - see base PresetDataset class.

        It uses both the SQLite DB (through dexed.PresetDatabase) and the pre-written files extracted from
        the DB (see dexed.PresetDatabase.write_all_presets_to_files(...)).

        :param algos: List. Can be used to limit the DX7 algorithms included in this dataset. Set to None
            to use all available algorithms
        :param restrict_to_labels: List of strings. If not None, presets of this dataset will be selected such
            that they are tagged with at least one of the given labels.
        :param constant_filter_and_tune_params: if True, the main filter and the main tune settings are default
        :param prevent_SH_LFO: if True, replaces the SH random LFO by a square-wave deterministic LFO
        :param check_constrains_consistency: Set to False when this dataset instance is used to pre-render
            audio files
        """
        super().__init__(note_duration, n_fft, fft_hop, midi_note, midi_velocity, n_mel_bins, mel_fmin, mel_fmax,
                         normalize_audio, spectrogram_min_dB, spectrogram_normalization)
        self.prevent_SH_LFO = prevent_SH_LFO
        self.constant_filter_and_tune_params = constant_filter_and_tune_params
        if check_constrains_consistency:
            assert self.check_audio_render_constraints_file()  # pre-rendered audio constraints consistency
        self.algos = algos if algos is not None else []
        self.restrict_to_labels = restrict_to_labels
        # - - - Full SQLite DB read and temp storage in np arrays - - -
        dexed_db = dexed.PresetDatabase()
        self.total_nb_presets = dexed_db.presets_mat.shape[0]
        self.total_nb_params = dexed_db.presets_mat.shape[1]
        self.learnable_params_idx = list(range(0, dexed_db.presets_mat.shape[1]))
        if self.constant_filter_and_tune_params:  # (see dexed_db_explore.ipynb)
            for idx in [0, 1, 2, 3, 13]:
                self.learnable_params_idx.remove(idx)
        # All oscillators are always ON (see dexed db exploration notebook)
        for col in [44, 66, 88, 110, 132, 154]:
            self.learnable_params_idx.remove(col)
        # - - - Valid presets - UIDs of presets, and not their database row index - - -
        # Select valid presets by algorithm
        if len(self.algos) == 0:  # All presets are valid
            self.valid_preset_UIDs = dexed_db.all_presets_df["index_preset"].values
        else:
            if len(self.algos) == 1:
                self.learnable_params_idx.remove(4)  # Algo parameter column idx
            valid_presets_row_indexes = list()
            for algo in self.algos:
                valid_presets_row_indexes += dexed_db.get_preset_indexes_for_algorithm(algo)
            self.valid_preset_UIDs = dexed_db.all_presets_df\
                .iloc[valid_presets_row_indexes]['index_preset'].values
        # Select valid presets by label. We build a list of list-indexes to remove
        if self.restrict_to_labels is not None:
            self.valid_preset_UIDs = [uid for uid in self.valid_preset_UIDs
                                      if any([self.is_label_included(l) for l in self.get_labels_name(uid)])]
        # - - - DB class deleted (we need a low memory usage for multi-process dataloaders) - - -
        del dexed_db

    @property
    def synth_name(self):  # Overrides parent abstract property
        return "Dexed"

    def get_preset_params(self, preset_UID):  # Overrides parent abstract method
        """ Reads the requested preset params from a .pickle file and applies the constraints (constant values,
        non-learnable params) of this class. """
        preset_params = dexed.PresetDatabase.get_preset_params_values_from_file(preset_UID)
        dexed.Dexed.set_all_oscillators_on_(preset_params)
        if self.constant_filter_and_tune_params:
            dexed.Dexed.set_default_general_filter_and_tune_params_(preset_params)
        if self.prevent_SH_LFO:
            dexed.Dexed.prevent_SH_LFO_(preset_params)
        return preset_params

    def is_label_included(self, label):
        """ Returns True if the label belongs to the restricted labels list. """
        if self.restrict_to_labels is None:
            return True
        else:
            return any([label == l_ for l_ in self.restrict_to_labels])

    def get_labels_tensor(self, preset_UID):  # TODO Overrides parent abstract method
        """ Returns a tensor of torch.int8 zeros and ones - each value is 1 if the preset is tagged with the
        corresponding label """
        return torch.tensor([1], dtype=torch.int8)  # 'NoLabel' is the only default label

    def get_labels_name(self, preset_UID):  # Overrides parent abstract method
        return dexed.PresetDatabase.get_preset_labels_from_file(preset_UID)

    @property
    def available_labels_names(self):  # Overrides parent abstract method
        """ Returns a tuple of string description of labels. """
        return dexed.PresetDatabase.get_available_labels()

    def _render_audio(self, preset_params, midi_note, midi_velocity):
        """ Renders audio on-the-fly and returns the computed audio waveform and sampling rate.

        :param preset_params: Constrained preset parameters (constraints from this class ctor args must have
            been applied before passing preset_params).
        """
        # reload the VST to prevent hanging notes/sounds
        dexed_renderer = dexed.Dexed(midi_note_duration_s=self.note_duration[0],
                                     render_duration_s=self.note_duration[0] + self.note_duration[1])
        dexed_renderer.assign_preset(dexed.PresetDatabase.get_params_in_plugin_format(preset_params))
        x_wav = dexed_renderer.render_note(midi_note, midi_velocity, normalize=self.normalize_audio)
        return x_wav, dexed_renderer.Fs

    @staticmethod
    def get_wav_file_path(preset_UID, midi_note, midi_velocity):
        """ Returns the path of a wav (from dexed_presets folder). """
        presets_folder = dexed.PresetDatabase._get_presets_folder()
        filename = "preset{:06d}_midi{:03d}vel{:03d}.wav".format(preset_UID, midi_note, midi_velocity)
        return presets_folder.joinpath(filename)

    @staticmethod
    def get_wav_file(preset_UID, midi_note, midi_velocity):  # Overrides parent abstract method
        return soundfile.read(DexedDataset.get_wav_file_path(preset_UID, midi_note, midi_velocity))

    def generate_wav_files(self):
        """ Reads all presets (names, param values, and labels) from .pickle and .txt files
         (see dexed.PresetDatabase.write_all_presets_to_files(...)) and renders them
         using attributes and constraints of this class (midi note, normalization, etc...)

         Floating-point .wav files will be stored in dexed presets' folder (see synth/dexed.py)

         Also writes a audio_render_constraints.json file that should be checked when loading data.
         """
        midi_note, midi_velocity = self.midi_note, self.midi_velocity
        for i in range(len(self)):   # TODO full dataset
            preset_UID = self.valid_preset_UIDs[i]
            preset_params = self.get_preset_params(preset_UID)  # Constrained params
            x_wav, Fs = self._render_audio(preset_params, midi_note, midi_velocity)  # Re-Loads the VST
            soundfile.write(self.get_wav_file_path(preset_UID, midi_note, midi_velocity),
                            x_wav, Fs, subtype='FLOAT')
            if i % 5000 == 0:
                print("Writing .wav files... ({}/{})".format(i, len(self)))
        print("Finished writing {} .wav files".format(len(self)))

    def write_audio_render_constraints_file(self):
        file_path = dexed.PresetDatabase._get_presets_folder().joinpath("audio_render_constraints_file.json")
        with open(file_path, 'w') as f:
            json.dump({'constant_filter_and_tune_params': self.constant_filter_and_tune_params,
                       'prevent_SH_LFO': self.prevent_SH_LFO}, f)

    def check_audio_render_constraints_file(self):
        """ Returns True if the constraints used to pre-rendered audio are the same as this instance constraints
        (S&H locked, filter/tune general params, ...) """
        file_path = dexed.PresetDatabase._get_presets_folder().joinpath("audio_render_constraints_file.json")
        with open(file_path, 'r') as f:
            constraints = json.load(f)
            return constraints['constant_filter_and_tune_params'] == self.constant_filter_and_tune_params\
                and constraints['prevent_SH_LFO'] == self.prevent_SH_LFO




if __name__ == "__main__":

    # ============== DATA RE-GENERATION - FROM config.py ==================
    regenerate_wav = False  # quite long (15min)
    regenerate_spectrograms_stats = False  # approx 3 min

    import sys
    sys.path.append(pathlib.Path(__file__).parent.parent)
    import config  # Dirty path trick to import config.py from project root dir

    dexed_dataset = DexedDataset(note_duration=config.model.note_duration,
                                 n_fft=config.model.stft_args[0], fft_hop=config.model.stft_args[1],
                                 n_mel_bins=config.model.mel_bins,
                                 spectrogram_normalization=None,  # No normalization: we want to compute stats
                                 spectrogram_min_dB=config.model.spectrogram_min_dB,
                                 check_constrains_consistency=False)
    print(dexed_dataset)

    dexed_dataset.write_audio_render_constraints_file()

    if regenerate_wav:
        # WRITE ALL WAV FILES (approx. 13Go for 5.0s audio)
        dexed_dataset.generate_wav_files()
    if regenerate_spectrograms_stats:
        # whole-dataset stats (for proper normalization)
        dexed_dataset.compute_and_store_spectrograms_stats()
    # ============== DATA RE-GENERATION - FROM config.py ==================



    # Dataloader debug tests
    if False:
        # Test dataload - to trigger potential errors
        # _, _, _ = dexed_dataset[0]

        dexed_dataloader = torch.utils.data.DataLoader(dexed_dataset, batch_size=128, shuffle=False,
                                                       num_workers=1)#os.cpu_count() * 9 // 10)
        t0 = time.time()
        for batch_idx, sample in enumerate(dexed_dataloader):
            print(batch_idx)
            print(sample)
            if batch_idx%10 == 0:
                print("batch {}".format(batch_idx))
        print("Full dataset read in {:.1f} minutes.".format((time.time() - t0) / 60.0))
